import json
import os
import sys
from pathlib import Path
import gc

import numpy as np
import pandas as pd
import pyarrow.parquet as pq
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, balanced_accuracy_score
from sklearn.preprocessing import RobustScaler

PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.attackers import KerasAttacker, LGBAttacker, KerasDualAttacker, CNNAttacker, KNNAttacker, XGBoostAttacker, TabNetAttacker
from src.targets.oracle_client import LocalOracleClient, create_oracle_from_name
from src.sampling import entropy_sampling
from sklearn_extra.cluster import KMedoids


def _clip_scale(scaler: RobustScaler, X: np.ndarray) -> np.ndarray:
    """Scale data vá»›i RobustScaler vÃ  clip vá» [-5, 5] giá»‘ng pipeline gá»‘c."""
    transformed = scaler.transform(X)
    return np.clip(transformed, -5, 5)


def _pad_or_truncate_features(X: np.ndarray, target_dim: int) -> np.ndarray:
    """
    Pad hoáº·c truncate features Ä‘á»ƒ khá»›p vá»›i target_dim.
    
    Args:
        X: Input features array (n_samples, n_features) hoáº·c (n_features,) cho single sample
        target_dim: Sá»‘ features mong muá»‘n
    
    Returns:
        X Ä‘Æ°á»£c pad/truncate Ä‘á»ƒ khá»›p vá»›i target_dim
    """
    # Xá»­ lÃ½ cáº£ 1D vÃ  2D arrays
    is_1d = len(X.shape) == 1
    if is_1d:
        X = X.reshape(1, -1)
    
    current_dim = X.shape[1]
    
    if current_dim == target_dim:
        # KhÃ´ng cáº§n thay Ä‘á»•i
        return X[0] if is_1d else X
    elif current_dim > target_dim:
        # Truncate: Cáº¯t bá» features thá»«a (giá»¯ N features Ä‘áº§u tiÃªn)
        X_truncated = X[:, :target_dim]
        return X_truncated[0] if is_1d else X_truncated
    else:
        # Padding: ThÃªm zeros vÃ o cuá»‘i
        n_samples = X.shape[0]
        n_pad = target_dim - current_dim
        pad_values = np.zeros((n_samples, n_pad), dtype=X.dtype)
        X_padded = np.hstack([X, pad_values])
        return X_padded[0] if is_1d else X_padded


def _resolve_optional_path(path_str: str | None) -> Path | None:
    if path_str is None:
        return None
    path_obj = Path(path_str)
    if not path_obj.is_absolute():
        path_obj = PROJECT_ROOT / path_obj
    return path_obj.resolve()


def get_feature_columns(parquet_path: str, label_col: str = "Label") -> list:
    """Láº¥y danh sÃ¡ch feature columns tá»« parquet file."""
    pq_file = pq.ParquetFile(parquet_path)
    return [name for name in pq_file.schema.names if name != label_col]


def load_data_from_parquet_stratified(
    parquet_path_label_0: str,
    parquet_path_label_1: str,
    feature_cols: list,
    label_col: str,
    take_rows: int = None,
    shuffle: bool = False,
    batch_size: int = 10000,
    seed: int = None,
) -> tuple:
    """
    Load dá»¯ liá»‡u tá»« 2 file Ä‘Ã£ chia sáºµn theo label (label_0 vÃ  label_1) vá»›i stratified sampling.
    Äáº£m báº£o cÃ¢n báº±ng class (50/50).
    """
    print(f"  ğŸ”„ Loading tá»« 2 file Ä‘Ã£ chia sáºµn theo label (stratified)...")
    print(f"     Class 0: {parquet_path_label_0}")
    print(f"     Class 1: {parquet_path_label_1}")
    
    # Load tá»« má»—i file
    X_0, y_0 = load_data_from_parquet(
        parquet_path_label_0, feature_cols, label_col, skip_rows=0, take_rows=None, shuffle=False, batch_size=batch_size, seed=None
    )
    X_1, y_1 = load_data_from_parquet(
        parquet_path_label_1, feature_cols, label_col, skip_rows=0, take_rows=None, shuffle=False, batch_size=batch_size, seed=None
    )
    
    print(f"  âœ… Loaded: {len(X_0)} samples class 0, {len(X_1)} samples class 1")
    
    # Stratified sampling: Láº¥y 50% tá»« má»—i class
    if take_rows is not None:
        samples_per_class = take_rows // 2
        rng = np.random.default_rng(seed)
        
        # Shuffle má»—i class
        indices_0 = np.arange(len(X_0))
        indices_1 = np.arange(len(X_1))
        rng.shuffle(indices_0)
        rng.shuffle(indices_1)
        
        # Láº¥y samples_per_class tá»« má»—i class
        selected_0 = indices_0[:min(samples_per_class, len(X_0))]
        selected_1 = indices_1[:min(samples_per_class, len(X_1))]
        
        # Náº¿u khÃ´ng Ä‘á»§ tá»« má»™t class, láº¥y thÃªm tá»« class kia
        if len(selected_0) < samples_per_class:
            needed = samples_per_class - len(selected_0)
            selected_1 = indices_1[:min(samples_per_class + needed, len(X_1))]
        elif len(selected_1) < samples_per_class:
            needed = samples_per_class - len(selected_1)
            selected_0 = indices_0[:min(samples_per_class + needed, len(X_0))]
        
        X_0 = X_0[selected_0]
        y_0 = y_0[selected_0]
        X_1 = X_1[selected_1]
        y_1 = y_1[selected_1]
        
        print(f"  âœ… Selected: {len(X_0)} samples class 0, {len(X_1)} samples class 1")
    
    # Káº¿t há»£p
    X_all = np.vstack([X_0, X_1])
    y_all = np.concatenate([y_0, y_1])
    
    # Shuffle náº¿u cáº§n
    if shuffle:
        print(f"  ğŸ”„ Äang shuffle {len(X_all):,} samples...")
        if seed is not None:
            rng = np.random.default_rng(seed)
            indices = rng.permutation(len(X_all))
        else:
            indices = np.random.permutation(len(X_all))
        X_all = X_all[indices]
        y_all = y_all[indices]
    
    return X_all, y_all


def load_data_from_parquet(
    parquet_path: str,
    feature_cols: list,
    label_col: str,
    skip_rows: int = 0,
    take_rows: int = None,
    shuffle: bool = False,
    batch_size: int = 10000,
    seed: int = None,
) -> tuple:
    """
    Load dá»¯ liá»‡u tá»« parquet file, loáº¡i bá» label -1 vÃ  tráº£ vá» X, y.
    Giá»‘ng logic trong final_model.ipynb nhÆ°ng khÃ´ng normalize (sáº½ normalize sau).
    
    Args:
        seed: Random seed cho shuffle. Náº¿u None thÃ¬ dÃ¹ng np.random khÃ´ng cÃ³ seed (khÃ´ng reproducible).
    """
    pq_file = pq.ParquetFile(parquet_path)
    all_X = []
    all_y = []
    rows_seen = 0
    emitted = 0
    removed_total = 0
    batch_count = 0

    try:
        total_batches = (pq_file.metadata.num_rows + batch_size - 1) // batch_size

        for batch in pq_file.iter_batches(batch_size=batch_size, columns=feature_cols + [label_col]):
            batch_count += 1
            batch_len = len(batch)
            batch_start = rows_seen
            rows_seen += batch_len

            if rows_seen <= skip_rows:
                if batch_count % 50 == 0:
                    print(f"  â³ ÄÃ£ xá»­ lÃ½ {batch_count}/{total_batches} batches (Ä‘ang skip)...")
                continue

            batch_df = batch.to_pandas()

            if skip_rows > batch_start:
                start_idx = skip_rows - batch_start
                batch_df = batch_df.iloc[start_idx:]

            if label_col in batch_df.columns:
                label_series = batch_df[label_col]
            else:
                alt_cols = [col for col in batch_df.columns if col.lower() == label_col.lower()]
                if alt_cols:
                    label_series = batch_df[alt_cols[0]]
                else:
                    raise KeyError(
                        f"Label column '{label_col}' khÃ´ng tá»“n táº¡i. CÃ¡c cá»™t: {list(batch_df.columns)[:5]}..."
                    )

            # Loáº¡i bá» label -1 (unlabeled)
            valid_mask = label_series != -1
            if not np.any(valid_mask):
                removed_total += len(label_series)
                del batch_df, label_series
                gc.collect()
                continue

            removed_total += int(np.sum(~valid_mask))
            batch_df = batch_df[valid_mask]
            label_series = label_series[valid_mask]

            if take_rows is not None:
                remaining = take_rows - emitted
                if remaining <= 0:
                    break
                if len(batch_df) > remaining:
                    batch_df = batch_df.iloc[:remaining]
                    label_series = label_series.iloc[:remaining]

            if batch_df.empty:
                del batch_df, label_series
                gc.collect()
                continue

            X = batch_df[feature_cols].values.astype(np.float32)
            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
            y = label_series.values.astype(np.int32)

            all_X.append(X)
            all_y.append(y)
            emitted += len(X)

            if batch_count % 20 == 0:
                del batch_df, label_series
                gc.collect()
                if take_rows is None:
                    print(f"  â³ ÄÃ£ xá»­ lÃ½ {batch_count}/{total_batches} batches, loaded {emitted:,} samples...")
                else:
                    print(
                        f"  â³ ÄÃ£ xá»­ lÃ½ {batch_count}/{total_batches} batches, loaded {emitted:,}/{take_rows:,} samples..."
                    )
            else:
                del batch_df, label_series

            if take_rows is not None and emitted >= take_rows:
                break

        if all_X:
            X_concat = np.concatenate(all_X, axis=0)
            y_concat = np.concatenate(all_y, axis=0)
            del all_X, all_y
            gc.collect()
        else:
            X_concat = np.empty((0, len(feature_cols)), dtype=np.float32)
            y_concat = np.empty((0,), dtype=np.int32)

        if shuffle and len(X_concat) > 0:
            print(f"  ğŸ”„ Äang shuffle {len(X_concat):,} samples...")
            if seed is not None:
                rng = np.random.default_rng(seed)
                indices = rng.permutation(len(X_concat))
            else:
                indices = np.random.permutation(len(X_concat))
            X_concat = X_concat[indices]
            y_concat = y_concat[indices]

        if removed_total > 0:
            print(f"  âš ï¸  ÄÃ£ loáº¡i bá» {removed_total:,} samples cÃ³ label -1 (unlabeled)")

        return X_concat, y_concat
    finally:
        del pq_file
        gc.collect()


def run_extraction(
    output_dir: Path,
    train_parquet: str = None,
    test_parquet: str = None,
    dataset: str = "ember",  # "ember" hoáº·c "somlap" - dataset Ä‘á»ƒ táº¥n cÃ´ng
    seed: int = 42,
    feature_dim: int = 2381,
    seed_size: int = None,  # Tá»± Ä‘á»™ng tÃ­nh tá»« total_budget náº¿u None
    val_size: int = None,    # Tá»± Ä‘á»™ng tÃ­nh tá»« total_budget náº¿u None
    eval_size: int = 4000,
    query_batch: int = None,  # Tá»± Ä‘á»™ng tÃ­nh tá»« total_budget náº¿u None
    num_rounds: int = None,  # Tá»± Ä‘á»™ng tÃ­nh tá»« total_budget náº¿u None
    total_budget: int = None,  # Tá»•ng query budget (seed + val + AL queries). Náº¿u Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, sáº½ tá»± Ä‘á»™ng tÃ­nh seed_size, val_size, query_batch, num_rounds
    num_epochs: int = 5,
    model_type: str = "h5",  # "h5" hoáº·c "lgb" - chá»‰ cáº§n náº¿u dÃ¹ng weights_path
    normalization_stats_path: str = None,  # Chá»‰ cáº§n náº¿u dÃ¹ng weights_path vá»›i model_type="lgb"
    attacker_type: str = None,  # "keras", "lgb", hoáº·c "dual" (dualDNN), None Ä‘á»ƒ tá»± Ä‘á»™ng chá»n theo model_type
    weights_path: str | None = None,
    model_name: str = None,  # TÃªn model (CEE, LEE, CSE, LSE) - Æ°u tiÃªn hÆ¡n weights_path
    threshold_optimization_metric: str = "f1",  # "f1", "accuracy", "balanced_accuracy" - metric Ä‘á»ƒ tá»‘i Æ°u threshold
    fixed_threshold: float | None = None,  # Náº¿u khÃ´ng None, sá»­ dá»¥ng threshold cá»‘ Ä‘á»‹nh thay vÃ¬ tá»‘i Æ°u
    surrogate_dir: str | None = None,  # Cho phÃ©p override thÆ° má»¥c lÆ°u surrogate
    surrogate_name: str | None = None,  # Cho phÃ©p override tÃªn file surrogate (khÃ´ng extension)
) -> dict:
    output_dir = Path(output_dir)
    rng = np.random.default_rng(seed)
    pool_exhausted_flag = False
    over_budget_flag = False

    # Chá»‰ set TF environment variables náº¿u dÃ¹ng Keras model
    if model_type == "h5" or attacker_type in ["keras", "dual"]:
        os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")
        os.environ.setdefault("TF_USE_LEGACY_KERAS", "1")

    # XÃ¡c Ä‘á»‹nh label column dá»±a trÃªn dataset
    dataset = dataset.lower()
    if dataset == "ember":
        label_col = "Label"
    elif dataset == "somlap":
        label_col = "class"
    else:
        raise ValueError(f"Dataset khÃ´ng Ä‘Æ°á»£c há»— trá»£: {dataset}. Chá»n 'ember' hoáº·c 'somlap'")
    
    # Auto-detect attacker_type náº¿u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    if attacker_type is None:
        attacker_type = "keras" if model_type == "h5" else "lgb"

    # QUAN TRá»ŒNG: TÃ­nh toÃ¡n seed_size, val_size, query_batch, num_rounds tá»« total_budget
    # Náº¿u total_budget Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, tá»± Ä‘á»™ng tÃ­nh cÃ¡c giÃ¡ trá»‹ nÃ y
    if total_budget is not None:
        # TÃ­nh seed_size = 10% cá»§a total_budget
        calculated_seed_size = int(total_budget * 0.1)
        # TÃ­nh val_size = 20% cá»§a total_budget
        calculated_val_size = int(total_budget * 0.2)
        # TÃ­nh AL_queries = 70% cá»§a total_budget (pháº§n cÃ²n láº¡i)
        AL_queries = total_budget - calculated_seed_size - calculated_val_size
        
        # Sá»­ dá»¥ng giÃ¡ trá»‹ Ä‘Ã£ tÃ­nh náº¿u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
        if seed_size is None:
            seed_size = calculated_seed_size
        if val_size is None:
            val_size = calculated_val_size
        
        # TÃ­nh query_batch vÃ  num_rounds tá»« AL_queries náº¿u chÆ°a Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
        if query_batch is None or num_rounds is None:
            # Máº·c Ä‘á»‹nh: chia AL_queries thÃ nh 5 rounds
            if num_rounds is None:
                num_rounds = 5
            if query_batch is None:
                query_batch = AL_queries // num_rounds
                # Äáº£m báº£o query_batch Ã— num_rounds = AL_queries (cÃ³ thá»ƒ lÃ m trÃ²n)
                if query_batch * num_rounds < AL_queries:
                    query_batch += 1
        
        print(f"\nğŸ“Š Query Budget Configuration (tá»« total_budget={total_budget:,}):")
        print(f"   Seed size: {seed_size:,} (10% cá»§a budget)")
        print(f"   Val size: {val_size:,} (20% cá»§a budget)")
        print(f"   AL queries: {AL_queries:,} (70% cá»§a budget)")
        print(f"   Query batch: {query_batch:,} queries/round")
        print(f"   Number of rounds: {num_rounds}")
        print(f"   Total queries (seed + val + AL): {seed_size + val_size + AL_queries:,}")
    else:
        # Náº¿u total_budget khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh, dÃ¹ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh
        if seed_size is None:
            seed_size = 2000
        if val_size is None:
            val_size = 1000
        if query_batch is None:
            query_batch = 2000
        if num_rounds is None:
            num_rounds = 5
        
        print(f"\nğŸ“Š Query Budget Configuration (giÃ¡ trá»‹ máº·c Ä‘á»‹nh):")
        print(f"   Seed size: {seed_size:,}")
        print(f"   Val size: {val_size:,}")
        print(f"   Query batch: {query_batch:,} queries/round")
        print(f"   Number of rounds: {num_rounds}")
        print(f"   AL queries: {query_batch * num_rounds:,}")
        print(f"   Total queries (seed + val + AL): {seed_size + val_size + query_batch * num_rounds:,}")

    # Debug: Log giÃ¡ trá»‹ train_parquet vÃ  test_parquet trÆ°á»›c khi xá»­ lÃ½
    print(f"\nğŸ” DEBUG: dataset={dataset}, train_parquet={train_parquet}, test_parquet={test_parquet}")

    # Load dá»¯ liá»‡u tá»« parquet files (EMBER hoáº·c SOMLAP)
    # QUAN TRá»ŒNG: Náº¿u train_parquet hoáº·c test_parquet Ä‘Ã£ Ä‘Æ°á»£c set (khÃ´ng pháº£i None),
    # cáº§n Ä‘áº£m báº£o chÃºng phÃ¹ há»£p vá»›i dataset Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
    if train_parquet is not None or test_parquet is not None:
        # Náº¿u Ä‘Ã£ Ä‘Æ°á»£c set, cáº§n validate xem cÃ³ khá»›p vá»›i dataset khÃ´ng
        if train_parquet is not None:
            train_path = Path(train_parquet)
            # Kiá»ƒm tra xem file cÃ³ pháº£i lÃ  EMBER file khi dataset lÃ  somlap khÃ´ng
            if dataset == "somlap" and ("ember" in str(train_path).lower() or "ember_2018" in str(train_path)):
                print(f"âš ï¸  WARNING: train_parquet Ä‘Æ°á»£c set lÃ  EMBER file nhÆ°ng dataset lÃ  SOMLAP!")
                print(f"   âš ï¸  Äang bá» qua train_parquet vÃ  sá»­ dá»¥ng dataset parameter Ä‘á»ƒ chá»n file Ä‘Ãºng")
                train_parquet = None
            elif dataset == "ember" and "somlap" in str(train_path).lower():
                print(f"âš ï¸  WARNING: train_parquet Ä‘Æ°á»£c set lÃ  SOMLAP file nhÆ°ng dataset lÃ  EMBER!")
                print(f"   âš ï¸  Äang bá» qua train_parquet vÃ  sá»­ dá»¥ng dataset parameter Ä‘á»ƒ chá»n file Ä‘Ãºng")
                train_parquet = None
        
        if test_parquet is not None:
            test_path = Path(test_parquet)
            # Kiá»ƒm tra xem file cÃ³ pháº£i lÃ  EMBER file khi dataset lÃ  somlap khÃ´ng
            if dataset == "somlap" and ("ember" in str(test_path).lower() or "ember_2018" in str(test_path)):
                print(f"âš ï¸  WARNING: test_parquet Ä‘Æ°á»£c set lÃ  EMBER file nhÆ°ng dataset lÃ  SOMLAP!")
                print(f"   âš ï¸  Äang bá» qua test_parquet vÃ  sá»­ dá»¥ng dataset parameter Ä‘á»ƒ chá»n file Ä‘Ãºng")
                test_parquet = None
            elif dataset == "ember" and "somlap" in str(test_path).lower():
                print(f"âš ï¸  WARNING: test_parquet Ä‘Æ°á»£c set lÃ  SOMLAP file nhÆ°ng dataset lÃ  EMBER!")
                print(f"   âš ï¸  Äang bá» qua test_parquet vÃ  sá»­ dá»¥ng dataset parameter Ä‘á»ƒ chá»n file Ä‘Ãºng")
                test_parquet = None
    
    if train_parquet is None:
        if dataset == "ember":
            # EMBER dataset: Thá»­ dÃ¹ng file Ä‘Ã£ chia sáºµn theo label trÆ°á»›c
            train_parquet_label_0 = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "train" / "train_ember_2018_v2_features_label_other_label_0.parquet")
            train_parquet_label_1 = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "train" / "train_ember_2018_v2_features_label_other_label_1.parquet")
            # Fallback vá» file cÅ© náº¿u khÃ´ng cÃ³ file má»›i
            train_parquet_old = str(PROJECT_ROOT / "data" / "train_ember_2018_v2_features_label_other.parquet")
            if Path(train_parquet_label_0).exists() and Path(train_parquet_label_1).exists():
                train_parquet = None  # Sáº½ dÃ¹ng stratified load tá»« 2 file
            elif Path(train_parquet_old).exists():
                train_parquet = train_parquet_old
            else:
                raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y EMBER train data táº¡i: {train_parquet_label_0} hoáº·c {train_parquet_old}")
        elif dataset == "somlap":
            # SOMLAP dataset
            train_parquet_path = PROJECT_ROOT / "data" / "SOMLAP" / "SOMLAP DATASET_train.parquet"
            if train_parquet_path.exists():
                train_parquet = str(train_parquet_path)
            else:
                raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y SOMLAP train data táº¡i: {train_parquet_path}")
    
    if test_parquet is None:
        if dataset == "ember":
            test_parquet_new = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "test" / "test_ember_2018_v2_features_label_other.parquet")
            test_parquet_old = str(PROJECT_ROOT / "data" / "test_ember_2018_v2_features_label_other.parquet")
            if Path(test_parquet_new).exists():
                test_parquet = test_parquet_new
            elif Path(test_parquet_old).exists():
                test_parquet = test_parquet_old
            else:
                raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y EMBER test data táº¡i: {test_parquet_new} hoáº·c {test_parquet_old}")
        elif dataset == "somlap":
            test_parquet_path = PROJECT_ROOT / "data" / "SOMLAP" / "SOMLAP DATASET_test.parquet"
            if test_parquet_path.exists():
                test_parquet = str(test_parquet_path)
            else:
                raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y SOMLAP test data táº¡i: {test_parquet_path}")

    print("=" * 60)
    print(f"ğŸ“Š Äang load dá»¯ liá»‡u {dataset.upper()}...")
    print("=" * 60)
    print(f"Dataset: {dataset.upper()}")
    print(f"Label column: {label_col}")
    print(f"Train file: {train_parquet if train_parquet else '(sáº½ tá»± Ä‘á»™ng chá»n dá»±a trÃªn dataset)'}")
    print(f"Test file: {test_parquet if test_parquet else '(sáº½ tá»± Ä‘á»™ng chá»n dá»±a trÃªn dataset)'}")

    # Láº¥y feature columns vÃ  xÃ¡c Ä‘á»‹nh feature_dim thá»±c táº¿ cá»§a dataset attack
    # Náº¿u train_parquet lÃ  None (dÃ¹ng stratified load tá»« 2 file - chá»‰ EMBER), dÃ¹ng má»™t trong 2 file hoáº·c test_parquet
    if train_parquet is None:
        # Chá»‰ cÃ³ thá»ƒ None vá»›i EMBER dataset (stratified loading)
        train_parquet_label_0 = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "train" / "train_ember_2018_v2_features_label_other_label_0.parquet")
        if Path(train_parquet_label_0).exists():
            feature_cols = get_feature_columns(train_parquet_label_0, label_col)
        elif test_parquet is not None:
            feature_cols = get_feature_columns(test_parquet, label_col)
        else:
            raise ValueError("KhÃ´ng thá»ƒ láº¥y feature columns: train_parquet lÃ  None vÃ  khÃ´ng cÃ³ file label_0 hoáº·c test_parquet")
    else:
        feature_cols = get_feature_columns(train_parquet, label_col)
    
    # LÆ°u sá»‘ features thá»±c táº¿ cá»§a dataset attack (Ä‘á»ƒ pad/truncate sau)
    dataset_attack_feature_dim = len(feature_cols)
    print(f"ğŸ“Š Dataset attack ({dataset.upper()}) cÃ³ {dataset_attack_feature_dim} features")
    
    # QUAN TRá»ŒNG: KHÃ”NG tá»± Ä‘á»™ng thay Ä‘á»•i feature_dim thÃ nh sá»‘ features cá»§a dataset attack!
    # feature_dim pháº£i Ä‘Æ°á»£c set dá»±a trÃªn target model, khÃ´ng pháº£i dataset attack
    # Dataset attack chá»‰ lÃ  nguá»“n dá»¯ liá»‡u, cáº§n pad/truncate Ä‘á»ƒ khá»›p vá»›i target model
    print(f"ğŸ“Š Specified feature_dim (tá»« target model hoáº·c default): {feature_dim}")
    
    # QUAN TRá»ŒNG: Validate vÃ  log thÃ´ng tin target model
    oracle_source = None
    required_feature_dim = None
    oracle_client = None
    model_file_name = None
    
    # Æ¯u tiÃªn sá»­ dá»¥ng model_name náº¿u Ä‘Æ°á»£c cung cáº¥p
    if model_name is not None:
        print(f"\nğŸ”„ Khá»Ÿi táº¡o target model tá»« tÃªn: {model_name.upper()}")
        print(f"   â„¹ï¸  Sáº½ tá»± Ä‘á»™ng detect model type vÃ  tÃ¬m normalization stats...")
        print(f"   ğŸ”’ BLACK BOX: Attacker chá»‰ biáº¿t tÃªn model, khÃ´ng biáº¿t implementation details")
        
        # Sá»­ dá»¥ng create_oracle_from_name - tá»± Ä‘á»™ng detect má»i thá»©
        # Tráº£ vá» BlackBoxOracleClient Ä‘á»ƒ áº©n implementation details
        oracle_client = create_oracle_from_name(
            model_name=model_name,
            threshold=0.5,
            feature_dim=feature_dim,
        )
        
        # Láº¥y thÃ´ng tin tá»« oracle client (chá»‰ Ä‘á»ƒ logging, khÃ´ng dÃ¹ng trong attack)
        # Trong black box attack thá»±c táº¿, attacker khÃ´ng nÃªn biáº¿t nhá»¯ng thÃ´ng tin nÃ y
        # NhÆ°ng Ä‘á»ƒ logging/debugging, váº«n láº¥y tá»« internal oracle
        if hasattr(oracle_client, '_oracle'):
            internal_oracle = oracle_client._oracle
            weights_path_abs = internal_oracle.model_path
            model_type = internal_oracle.model_type
            # Khi dÃ¹ng model_name, normalization_stats_path Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng tÃ¬m vÃ  truyá»n vÃ o oracle
            # KhÃ´ng cáº§n kiá»ƒm tra láº¡i á»Ÿ Ä‘Ã¢y
            normalization_stats_path = "auto-detected"  # ÄÃ¡nh dáº¥u Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng detect
        else:
            # Fallback náº¿u khÃ´ng cÃ³ _oracle (trÆ°á»ng há»£p dÃ¹ng LocalOracleClient trá»±c tiáº¿p)
            weights_path_abs = oracle_client.model_path
            model_type = oracle_client.model_type
            normalization_stats_path = getattr(oracle_client, 'normalization_stats_path', None)
        
        model_file_name = Path(weights_path_abs).name
        model_file_size = Path(weights_path_abs).stat().st_size / (1024 * 1024)  # MB
        oracle_source = weights_path_abs
        
        print(f"   âœ… Target model file: {model_file_name}")
        print(f"   âœ… Model path (absolute): {weights_path_abs}")
        print(f"   âœ… Model type: {model_type.upper()}")
        print(f"   âœ… Model size: {model_file_size:.2f} MB")
        print(f"   âš ï¸  LÆ¯U Ã: ThÃ´ng tin trÃªn chá»‰ Ä‘á»ƒ logging, attacker khÃ´ng nÃªn biáº¿t trong black box attack thá»±c táº¿")
        
        required_feature_dim = oracle_client.get_required_feature_dim()
    else:
        # Sá»­ dá»¥ng cÃ¡ch cÅ© vá»›i weights_path
        if weights_path is None:
            raise ValueError("Pháº£i cung cáº¥p weights_path hoáº·c model_name cho oracle module.")
        weights_path_abs = str(Path(weights_path).resolve())
        if not Path(weights_path_abs).exists():
            raise FileNotFoundError(f"âŒ Target model khÃ´ng tá»“n táº¡i: {weights_path_abs}")
        
        model_file_name = Path(weights_path_abs).name
        model_file_size = Path(weights_path_abs).stat().st_size / (1024 * 1024)  # MB
        oracle_source = weights_path_abs
        
        print(f"\nğŸ”„ Khá»Ÿi táº¡o target model ({model_type.upper()}) vá»›i feature_dim={feature_dim}...")
        print(f"   âœ… Target model file: {model_file_name}")
        print(f"   âœ… Model path (absolute): {weights_path_abs}")
        print(f"   âœ… Model size: {model_file_size:.2f} MB")
        
        if weights_path != weights_path_abs:
            print(f"   âš ï¸  Path Ä‘Æ°á»£c resolve: {weights_path} -> {weights_path_abs}")
        
        if model_type == "lgb":
            if normalization_stats_path is None:
                raise ValueError(
                    "normalization_stats_path pháº£i Ä‘Æ°á»£c cung cáº¥p khi model_type='lgb'. "
                    "Vui lÃ²ng cung cáº¥p Ä‘Æ°á»ng dáº«n tá»›i file normalization_stats.npz"
                )
            if isinstance(normalization_stats_path, str):
                stats_path_abs = str(Path(normalization_stats_path).resolve())
                if not Path(stats_path_abs).exists():
                    raise FileNotFoundError(f"âŒ Normalization stats khÃ´ng tá»“n táº¡i: {stats_path_abs}")
                normalization_stats_path = stats_path_abs
            
            print(f"   âœ… Normalization stats file: {Path(normalization_stats_path).name}")
            print(f"   âœ… Stats path (absolute): {normalization_stats_path}")
        else:
            normalization_stats_path = None
        
        # Táº¡o oracle client vá»›i weights_path (cÃ¡ch cÅ©)
        oracle_client = LocalOracleClient(
            model_type=model_type,
            model_path=weights_path_abs,
            normalization_stats_path=normalization_stats_path,
            threshold=0.5,
            feature_dim=feature_dim,
        )
        required_feature_dim = oracle_client.get_required_feature_dim()
    required_feature_dim = oracle_client.get_required_feature_dim()
    
    # QUAN TRá»ŒNG: Surrogate model pháº£i cÃ³ sá»‘ features báº±ng vá»›i target model
    # Náº¿u required_feature_dim khÃ´ng None, dÃ¹ng nÃ³ cho surrogate model
    # Náº¿u None (cÃ³ preprocessing layer), dÃ¹ng feature_dim hiá»‡n táº¡i
    if required_feature_dim is None:
        # Target model cÃ³ preprocessing layer - sáº½ tá»± Ä‘á»™ng map
        surrogate_feature_dim = feature_dim
        print(f"   âœ… Target model cÃ³ preprocessing layer - sáº½ tá»± Ä‘á»™ng map tá»« {feature_dim} Ä‘áº·c trÆ°ng")
        print(f"   âœ… Surrogate model sáº½ dÃ¹ng {surrogate_feature_dim} features (tá»« feature_dim)")
    else:
        # Target model yÃªu cáº§u sá»‘ features cá»¥ thá»ƒ
        surrogate_feature_dim = required_feature_dim
        print(f"   âœ… Target model yÃªu cáº§u {required_feature_dim} Ä‘áº·c trÆ°ng")
        print(f"   âœ… Surrogate model sáº½ dÃ¹ng {surrogate_feature_dim} features (tá»« target model)")
        
        # So sÃ¡nh vá»›i dataset attack
        if dataset_attack_feature_dim > required_feature_dim:
            print(f"   âš ï¸  Dataset attack cÃ³ {dataset_attack_feature_dim} Ä‘áº·c trÆ°ng, sáº½ tá»± Ä‘á»™ng cáº¯t bá» {dataset_attack_feature_dim - required_feature_dim} Ä‘áº·c trÆ°ng thá»«a")
            print(f"      (Giá»¯ {required_feature_dim} features Ä‘áº§u tiÃªn)")
        elif dataset_attack_feature_dim < required_feature_dim:
            print(f"   âš ï¸  Dataset attack cÃ³ {dataset_attack_feature_dim} Ä‘áº·c trÆ°ng, nhÆ°ng target model yÃªu cáº§u {required_feature_dim} Ä‘áº·c trÆ°ng")
            print(f"   âœ… Sáº½ tá»± Ä‘á»™ng PADDING thÃªm {required_feature_dim - dataset_attack_feature_dim} Ä‘áº·c trÆ°ng (zeros) trÆ°á»›c khi query oracle vÃ  train surrogate")
            print(f"      LÆ°u Ã½: Padding cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n Ä‘á»™ chÃ­nh xÃ¡c cá»§a attack")
        else:
            print(f"   âœ… Dataset attack cÃ³ {dataset_attack_feature_dim} features, khá»›p vá»›i target model ({required_feature_dim})")

    # QUAN TRá»ŒNG: Load Ä‘á»§ thief dataset Ä‘á»ƒ cÃ³ thá»ƒ chá»n máº«u sau nÃ y
    # Pool KHÃ”NG Ä‘Æ°á»£c chá»n trÆ°á»›c, mÃ  tÃ­ch lÅ©y dáº§n tá»« seed
    # Cáº§n load: seed + val + AL_queries + buffer (Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»§ máº«u)
    AL_queries_needed = query_batch * num_rounds
    buffer_size = int(AL_queries_needed * 0.2)  # Buffer 20% Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»§ máº«u
    seed_val_size = seed_size + val_size
    total_needed = seed_val_size + AL_queries_needed + buffer_size
    
    print(f"\nğŸ”„ Äang load thief dataset ({total_needed:,} samples: {seed_size:,} seed + {val_size:,} val + {AL_queries_needed:,} AL queries + {buffer_size:,} buffer)...")
    
    # Load train data - xá»­ lÃ½ khÃ¡c nhau cho EMBER vÃ  SOMLAP
    if dataset == "ember":
        # EMBER: Cáº¢I TIáº¾N: Sá»­ dá»¥ng file Ä‘Ã£ chia sáºµn theo label náº¿u cÃ³
        train_parquet_label_0 = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "train" / "train_ember_2018_v2_features_label_other_label_0.parquet")
        train_parquet_label_1 = str(PROJECT_ROOT / "data" / "ember_2018_v2" / "train" / "train_ember_2018_v2_features_label_other_label_1.parquet")
        
        if Path(train_parquet_label_0).exists() and Path(train_parquet_label_1).exists():
            # Sá»­ dá»¥ng file Ä‘Ã£ chia sáºµn theo label (stratified loading)
            # QUAN TRá»ŒNG: Load cáº£ ground truth labels tá»« train data (khÃ´ng query oracle!)
            X_train_all, y_train_all_gt = load_data_from_parquet_stratified(
                train_parquet_label_0, train_parquet_label_1, feature_cols, label_col,
                take_rows=total_needed, shuffle=True, seed=seed
            )
            print(f"âœ… Train data loaded (stratified): {X_train_all.shape}")
        else:
            # Fallback: DÃ¹ng file cÅ©
            if train_parquet is None:
                raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y EMBER train data files. ÄÃ£ tÃ¬m táº¡i:\n  - {train_parquet_label_0}\n  - {train_parquet_label_1}")
            X_train_all, y_train_all_gt = load_data_from_parquet(
                train_parquet, feature_cols, label_col, skip_rows=0, take_rows=total_needed, shuffle=True, seed=seed
            )
            print(f"âœ… Train data loaded: {X_train_all.shape}")
    elif dataset == "somlap":
        # SOMLAP: Chá»‰ cÃ³ 1 file duy nháº¥t, khÃ´ng cÃ³ stratified files
        if train_parquet is None:
            raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y SOMLAP train data file")
        X_train_all, y_train_all_gt = load_data_from_parquet(
            train_parquet, feature_cols, label_col, skip_rows=0, take_rows=total_needed, shuffle=True, seed=seed
        )
        print(f"âœ… Train data loaded: {X_train_all.shape}")
    else:
        raise ValueError(f"Dataset khÃ´ng Ä‘Æ°á»£c há»— trá»£: {dataset}")

    train_dist = dict(zip(*np.unique(y_train_all_gt, return_counts=True)))
    print(f"   ğŸ“Š Train data distribution (ground truth): {train_dist}")
    
    # QUAN TRá»ŒNG: Pad/truncate data tá»« dataset attack Ä‘á»ƒ khá»›p vá»›i surrogate_feature_dim
    if dataset_attack_feature_dim != surrogate_feature_dim:
        print(f"\nğŸ”„ Äang pad/truncate train data tá»« {dataset_attack_feature_dim} lÃªn {surrogate_feature_dim} features...")
        X_train_all = _pad_or_truncate_features(X_train_all, surrogate_feature_dim)
        print(f"   âœ… Train data shape sau pad/truncate: {X_train_all.shape}")

    # Cáº¢I TIáº¾N: Stratified split cho Seed vÃ  Val Ä‘á»ƒ cÃ¢n báº±ng class
    # Sá»­ dá»¥ng ground truth labels tá»« train data (KHÃ”NG query oracle!)
    print(f"\nğŸ”„ Chia Seed vÃ  Val vá»›i stratified sampling (cÃ¢n báº±ng class, dÃ¹ng ground truth labels)...")
    rng = np.random.default_rng(seed)
    
    # TÃ¡ch indices theo class (dÃ¹ng ground truth labels)
    class_0_indices = np.where(y_train_all_gt == 0)[0]
    class_1_indices = np.where(y_train_all_gt == 1)[0]
    
    # Shuffle má»—i class
    rng.shuffle(class_0_indices)
    rng.shuffle(class_1_indices)
    
    # Chia seed: 50% tá»« má»—i class
    seed_per_class = seed_size // 2
    seed_class_0_idx = class_0_indices[:seed_per_class]
    seed_class_1_idx = class_1_indices[:min(seed_per_class, len(class_1_indices))]
    
    # Náº¿u khÃ´ng Ä‘á»§ class 1, láº¥y thÃªm tá»« class 0
    if len(seed_class_1_idx) < seed_per_class:
        needed = seed_per_class - len(seed_class_1_idx)
        seed_class_0_idx = np.concatenate([seed_class_0_idx, class_0_indices[seed_per_class:seed_per_class+needed]])
    
    seed_indices = np.concatenate([seed_class_0_idx, seed_class_1_idx])
    rng.shuffle(seed_indices)  # Shuffle láº¡i Ä‘á»ƒ trá»™n classes
    
    # Cáº­p nháº­t class indices (loáº¡i bá» Ä‘Ã£ dÃ¹ng cho seed)
    class_0_indices = class_0_indices[len(seed_class_0_idx):]
    class_1_indices = class_1_indices[len(seed_class_1_idx):]
    
    # Chia val: 50% tá»« má»—i class (tá»« pháº§n cÃ²n láº¡i)
    val_per_class = val_size // 2
    val_class_0_idx = class_0_indices[:val_per_class]
    val_class_1_idx = class_1_indices[:min(val_per_class, len(class_1_indices))]
    
    # Náº¿u khÃ´ng Ä‘á»§ class 1, láº¥y thÃªm tá»« class 0
    if len(val_class_1_idx) < val_per_class:
        needed = val_per_class - len(val_class_1_idx)
        val_class_0_idx = np.concatenate([val_class_0_idx, class_0_indices[val_per_class:val_per_class+needed]])
    
    val_indices = np.concatenate([val_class_0_idx, val_class_1_idx])
    rng.shuffle(val_indices)  # Shuffle láº¡i Ä‘á»ƒ trá»™n classes
    
    # Láº¥y seed vÃ  val
    X_seed = X_train_all[seed_indices]
    X_val = X_train_all[val_indices]
    
    # QUAN TRá»ŒNG: Pháº§n cÃ²n láº¡i giá»¯ lÃ m unlabeled pool (KHÃ”NG query trÆ°á»›c)
    # Pool sáº½ tÃ­ch lÅ©y dáº§n tá»« seed, sau Ä‘Ã³ thÃªm cÃ¡c máº«u Ä‘Æ°á»£c AL chá»n
    used_indices = np.concatenate([seed_indices, val_indices])
    unlabeled_pool_indices = np.setdiff1d(np.arange(len(X_train_all)), used_indices)
    X_unlabeled_pool = X_train_all[unlabeled_pool_indices]
    y_unlabeled_pool_gt = y_train_all_gt[unlabeled_pool_indices]  # Ground truth labels Ä‘á»ƒ pre-filtering
    
    # Kiá»ƒm tra xem cÃ³ Ä‘á»§ unlabeled pool khÃ´ng
    AL_queries_needed = query_batch * num_rounds
    available_unlabeled = len(unlabeled_pool_indices)
    if available_unlabeled < AL_queries_needed:
        print(f"   âš ï¸  Cáº¢NH BÃO: Unlabeled pool ({available_unlabeled:,}) < AL queries cáº§n ({AL_queries_needed:,})")
        print(f"   ğŸ’¡ CÃ³ thá»ƒ sáº½ thiáº¿u queries trong quÃ¡ trÃ¬nh active learning")
        if available_unlabeled < AL_queries_needed * 0.9:
            raise ValueError(
                f"KhÃ´ng Ä‘á»§ unlabeled pool! Available: {available_unlabeled:,}, "
                f"Required: {AL_queries_needed:,} (query_batch={query_batch:,} Ã— num_rounds={num_rounds})"
            )
    
    # Log distribution (ground truth)
    seed_dist_gt = dict(zip(*np.unique(y_train_all_gt[seed_indices], return_counts=True)))
    val_dist_gt = dict(zip(*np.unique(y_train_all_gt[val_indices], return_counts=True)))
    unlabeled_pool_dist_gt = dict(zip(*np.unique(y_unlabeled_pool_gt, return_counts=True)))
    print(f"   âœ… Seed distribution (stratified, ground truth): {seed_dist_gt}")
    print(f"   âœ… Val distribution (stratified, ground truth): {val_dist_gt}")
    print(f"   âœ… Unlabeled pool distribution (ground truth from thief dataset): {unlabeled_pool_dist_gt}")
    print(f"   âœ… Unlabeled pool size: {X_unlabeled_pool.shape[0]:,} samples (sáº½ Ä‘Æ°á»£c chá»n dáº§n trong AL)")
    print(f"      - AL queries cáº§n: {AL_queries_needed:,} (query_batch={query_batch:,} Ã— num_rounds={num_rounds})")
    del X_train_all
    gc.collect()

    # Load eval set tá»« test file
    # QUAN TRá»ŒNG: Load cáº£ ground truth labels Ä‘á»ƒ tÃ­nh accuracy chÃ­nh xÃ¡c
    print(f"\nğŸ”„ Äang load eval set ({eval_size:,} samples)...")
    # Test data cÃ³ thá»ƒ dÃ¹ng file cÅ© hoáº·c file má»›i
    X_eval, y_eval_gt = load_data_from_parquet(
        test_parquet, feature_cols, label_col, skip_rows=0, take_rows=eval_size, shuffle=True, seed=seed
    )
    print(f"âœ… Eval set: {X_eval.shape}")
    print(f"âœ… Ground truth labels: {y_eval_gt.shape}")
    
    # QUAN TRá»ŒNG: Pad/truncate eval data Ä‘á»ƒ khá»›p vá»›i surrogate_feature_dim
    if dataset_attack_feature_dim != surrogate_feature_dim:
        print(f"ğŸ”„ Äang pad/truncate eval data tá»« {dataset_attack_feature_dim} lÃªn {surrogate_feature_dim} features...")
        X_eval = _pad_or_truncate_features(X_eval, surrogate_feature_dim)
        print(f"   âœ… Eval data shape sau pad/truncate: {X_eval.shape}")

    print(f"\nğŸ“Š Data split:")
    print(f"  Seed: {X_seed.shape[0]:,}")
    print(f"  Val: {X_val.shape[0]:,}")
    print(f"  Unlabeled pool: {X_unlabeled_pool.shape[0]:,}")
    print(f"  Eval: {X_eval.shape[0]:,}")

    # QUAN TRá»ŒNG: Xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c khi query oracle
    # QUAN TRá»ŒNG: Scale data dá»±a trÃªn MODEL_TYPE Cá»¦A ORACLE (target model), KHÃ”NG pháº£i attacker_type!
    # - Vá»›i Keras/H5 Oracle: Cáº§n scale data vá»›i RobustScaler (model Ä‘Æ°á»£c train vá»›i scaled data)
    # - Vá»›i LightGBM Oracle: FlexibleLGBTarget sáº½ tá»± Ä‘á»™ng normalize náº¿u cÃ³ normalization_stats_path
    #   KHÃ”NG Ä‘Æ°á»£c scale vá»›i RobustScaler - chá»‰ cáº§n raw data!
    # - attacker_type chá»‰ áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡ch train surrogate model, khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡ch query oracle
    scaler = None
    X_eval_s = None
    X_seed_s = None
    X_val_s = None
    X_pool_s = None
    
    # Láº¥y model_type thá»±c táº¿ cá»§a oracle (khÃ´ng pháº£i attacker_type)
    oracle_model_type = model_type  # Náº¿u dÃ¹ng model_name, model_type Ä‘Ã£ Ä‘Æ°á»£c detect tá»« oracle_client
    
    # Kiá»ƒm tra xem oracle cÃ³ normalization_stats_path hay khÃ´ng
    oracle_has_normalization_stats = False
    if oracle_model_type == "h5":
        # Kiá»ƒm tra tá»« oracle client xem cÃ³ normalization stats khÃ´ng
        if hasattr(oracle_client, '_oracle'):
            # BlackBoxOracleClient -> LocalOracleClient -> FlexibleKerasTarget
            internal_oracle = oracle_client._oracle._oracle if hasattr(oracle_client._oracle, '_oracle') else oracle_client._oracle
            oracle_has_normalization_stats = getattr(internal_oracle, 'use_normalization', False)
        elif hasattr(oracle_client, '_oracle') and hasattr(oracle_client._oracle, 'use_normalization'):
            # LocalOracleClient -> FlexibleKerasTarget
            oracle_has_normalization_stats = oracle_client._oracle.use_normalization
        # Hoáº·c kiá»ƒm tra tá»« normalization_stats_path variable
        if not oracle_has_normalization_stats:
            oracle_has_normalization_stats = (normalization_stats_path is not None and 
                                             normalization_stats_path != "auto-detected" and
                                             normalization_stats_path != "")
    
    
    if oracle_model_type == "h5":
        if oracle_has_normalization_stats:
            # Keras/H5 Oracle cÃ³ normalization_stats: Oracle sáº½ tá»± Ä‘á»™ng normalize vÃ  clip
            # KHÃ”NG scale vá»›i RobustScaler - chá»‰ cáº§n raw data!
            print(f"\nğŸ”„ Oracle cÃ³ normalization stats - Oracle sáº½ tá»± Ä‘á»™ng normalize vÃ  clip")
            print(f"   âš ï¸  KHÃ”NG scale vá»›i RobustScaler - dÃ¹ng raw data Ä‘á»ƒ query oracle")
            
            # DÃ¹ng raw data Ä‘á»ƒ query oracle (oracle sáº½ tá»± normalize vÃ  clip)
            X_eval_s = X_eval
            X_seed_s = X_seed
            X_val_s = X_val
            
            # Láº¥y nhÃ£n tá»« oracle (Vá»šI RAW DATA - oracle sáº½ tá»± normalize vÃ  clip)
            print(f"\nğŸ”„ Äang láº¥y nhÃ£n tá»« oracle (vá»›i raw data - oracle sáº½ tá»± normalize vÃ  clip)...")
            y_eval = oracle_client.predict(X_eval_s)
            y_seed = oracle_client.predict(X_seed_s)
            y_val = oracle_client.predict(X_val_s)
            
            # Náº¿u attacker cáº§n scaled data cho training, táº¡o scaler riÃªng
            if attacker_type in ["keras", "dual", "cnn"]:
                print(f"\nâš ï¸  LÆ¯U Ã: Oracle tá»± normalize, nhÆ°ng surrogate lÃ  {attacker_type} (cáº§n scaled data)")
            elif attacker_type in ["xgb", "tabnet"]:
                print(f"\nâœ… Oracle tá»± normalize, surrogate lÃ  {attacker_type} (khÃ´ng cáº§n scaled data)")
                print(f"   ğŸ”„ Sáº½ scale data riÃªng cho surrogate model training sau...")
                scaler = RobustScaler()
                scaler.fit(np.vstack([X_seed, X_val, X_unlabeled_pool]))
                # Táº¡o scaled version cho surrogate training
                X_eval_s = _clip_scale(scaler, X_eval)
                X_seed_s = _clip_scale(scaler, X_seed)
                X_val_s = _clip_scale(scaler, X_val)
        else:
            # Keras/H5 Oracle KHÃ”NG cÃ³ normalization_stats: Cáº§n scale vá»›i RobustScaler
            print(f"\nğŸ”„ Äang scale dá»¯ liá»‡u trÆ°á»›c khi query oracle (Keras/H5 Oracle khÃ´ng cÃ³ normalization stats, cáº§n scaled data)...")
            scaler = RobustScaler()
            scaler.fit(np.vstack([X_seed, X_val, X_unlabeled_pool]))

            X_eval_s = _clip_scale(scaler, X_eval)
            X_seed_s = _clip_scale(scaler, X_seed)
            X_val_s = _clip_scale(scaler, X_val)
            # X_unlabeled_pool_s sáº½ Ä‘Æ°á»£c táº¡o sau trong AL loop náº¿u cáº§n
            
            print(f"âœ… ÄÃ£ scale dá»¯ liá»‡u")
            print(f"   - X_eval_s shape: {X_eval_s.shape}")
            print(f"   - X_seed_s shape: {X_seed_s.shape}")
            print(f"   - X_val_s shape: {X_val_s.shape}")
            print(f"   - X_unlabeled_pool_s: sáº½ Ä‘Æ°á»£c táº¡o sau trong AL loop náº¿u cáº§n")
            
            # Láº¥y nhÃ£n tá»« oracle (Vá»šI Dá»® LIá»†U ÄÃƒ SCALE)
            print(f"\nğŸ”„ Äang láº¥y nhÃ£n tá»« oracle (vá»›i dá»¯ liá»‡u Ä‘Ã£ scale cho Keras Oracle)...")
            y_eval = oracle_client.predict(X_eval_s)
            y_seed = oracle_client.predict(X_seed_s)
            y_val = oracle_client.predict(X_val_s)
    else:
        # Non-Keras Oracle (LightGBM / XGBoost / TabNet / sklearn):
        # - Oracle luÃ´n nháº­n raw features
        # - Náº¿u cáº§n normalize (LightGBM/TabNet), oracle sáº½ tá»± xá»­ lÃ½ ná»™i bá»™
        print(f"\nğŸ”„ Äang láº¥y nhÃ£n tá»« oracle ({oracle_model_type.upper()} Oracle - dÃ¹ng raw features, preprocessing ná»™i bá»™ náº¿u cáº§n)...")
        y_eval = oracle_client.predict(X_eval)
        y_seed = oracle_client.predict(X_seed)
        y_val = oracle_client.predict(X_val)
        
        # Vá»›i cÃ¡c oracle khÃ´ng pháº£i Keras, KHÃ”NG scale data khi query oracle
        X_eval_s = X_eval
        X_seed_s = X_seed
        X_val_s = X_val
        # X_unlabeled_pool_s sáº½ Ä‘Æ°á»£c táº¡o sau trong AL loop náº¿u cáº§n
        
        # Náº¿u attacker_type lÃ  keras/dual/cnn (cáº§n scaled data cho training),
        # cáº§n scale riÃªng cho surrogate model training sau nÃ y
        if attacker_type in ["keras", "dual", "cnn"]:
            print(f"\nâš ï¸  LÆ¯U Ã: Oracle lÃ  {oracle_model_type.upper()} (raw data), nhÆ°ng surrogate lÃ  {attacker_type} (cáº§n scaled data)")
        elif attacker_type in ["xgb", "tabnet"]:
            # Oracle (lgb/xgb/tabnet/sklearn) lÃ m viá»‡c trá»±c tiáº¿p trÃªn raw features.
            # Surrogate xgb/tabnet thÆ°á»ng huáº¥n luyá»‡n tá»‘t hÆ¡n vá»›i dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c scale,
            # nÃªn ta chá»‰ scale báº£n sao dÃ¹ng cho training/inference surrogate.
            print(f"\nâœ… Oracle lÃ  {oracle_model_type.upper()} (raw data), surrogate lÃ  {attacker_type} (oracle KHÃ”NG scale, chá»‰ surrogate Ä‘Æ°á»£c scale)")
            print(f"   ğŸ”„ Sáº½ scale dá»¯ liá»‡u RIÃŠNG cho surrogate model training (khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n oracle)")
            scaler = RobustScaler()
            scaler.fit(np.vstack([X_seed, X_val, X_unlabeled_pool]))
            # Táº¡o scaled version cho surrogate training
            X_eval_s = _clip_scale(scaler, X_eval)
            X_seed_s = _clip_scale(scaler, X_seed)
            X_val_s = _clip_scale(scaler, X_val)
            # X_unlabeled_pool_s sáº½ Ä‘Æ°á»£c táº¡o sau trong AL loop náº¿u cáº§n
    print(f"âœ… Oracle labels retrieved")
    eval_dist = dict(zip(*np.unique(y_eval, return_counts=True)))
    seed_dist = dict(zip(*np.unique(y_seed, return_counts=True)))
    val_dist = dict(zip(*np.unique(y_val, return_counts=True)))
    print(f"  Eval distribution: {eval_dist}")
    print(f"  Seed distribution: {seed_dist}")
    print(f"  Val distribution: {val_dist}")
    
    # QUAN TRá»ŒNG: ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a oracle vá»›i ground truth
    # Äiá»u nÃ y giÃºp giáº£i thÃ­ch sá»± khÃ¡c biá»‡t giá»¯a val_accuracy (vs oracle) vÃ  final accuracy (vs ground truth)
    oracle_acc_vs_gt = accuracy_score(y_eval_gt, y_eval)
    print(f"\nğŸ“Š ÄÃ¡nh giÃ¡ Oracle (Target Model):")
    print(f"   Oracle accuracy vs Ground Truth: {oracle_acc_vs_gt:.4f} ({oracle_acc_vs_gt*100:.2f}%)")
    print(f"   âš ï¸  LÆ¯U Ã: Val accuracy trong training Ä‘Æ°á»£c tÃ­nh vá»›i oracle labels (khÃ´ng pháº£i ground truth)")
    print(f"   âš ï¸  Final accuracy Ä‘Æ°á»£c tÃ­nh vá»›i ground truth labels")
    print(f"   ğŸ’¡ Náº¿u oracle khÃ´ng chÃ­nh xÃ¡c 100%, sáº½ cÃ³ sá»± khÃ¡c biá»‡t giá»¯a val_accuracy vÃ  final accuracy")
    
    # KIá»‚M TRA: Náº¿u oracle predict táº¥t cáº£ lÃ  má»™t class, cÃ³ thá»ƒ cÃ³ váº¥n Ä‘á»
    all_distributions = [eval_dist, seed_dist, val_dist]
    all_single_class = all(len(d) == 1 for d in all_distributions)
    if all_single_class:
        print(f"\nâš ï¸  Cáº¢NH BÃO: Oracle Ä‘ang predict táº¥t cáº£ lÃ  má»™t class duy nháº¥t!")
        print(f"   Äiá»u nÃ y cÃ³ thá»ƒ do:")
        print(f"   1. Oracle threshold quÃ¡ cao/tháº¥p")
        print(f"   2. Dá»¯ liá»‡u thá»±c sá»± chá»‰ cÃ³ má»™t class")
        print(f"   3. Oracle model cÃ³ váº¥n Ä‘á»")
        if not oracle_client.supports_probabilities():
            print(f"   â„¹ï¸  Oracle khÃ´ng há»— trá»£ probabilities -> bá» qua Ä‘iá»u chá»‰nh threshold tá»± Ä‘á»™ng.")
        else:
            print(f"   ğŸ’¡ Sáº½ thá»­ kiá»ƒm tra probabilities vÃ  cÃ³ thá»ƒ Ä‘iá»u chá»‰nh threshold...")
            try:
                test_sample_size = min(100, X_eval_s.shape[0])
                test_indices = rng.choice(X_eval_s.shape[0], size=test_sample_size, replace=False)
                test_data = X_eval_s[test_indices]
                test_probs = oracle_client.predict_proba(test_data)
                print(f"   ğŸ“Š Test probabilities trÃªn {test_sample_size} samples:")
                print(f"      Range: [{test_probs.min():.4f}, {test_probs.max():.4f}]")
                print(f"      Mean: {test_probs.mean():.4f}, Median: {np.median(test_probs):.4f}")
                print(f"      Threshold hiá»‡n táº¡i: {oracle_client.get_threshold():.4f}")
                
                current_thresh = oracle_client.get_threshold()
                if test_probs.min() < current_thresh < test_probs.max():
                    print(f"   ğŸ’¡ Probabilities cÃ³ cáº£ dÆ°á»›i vÃ  trÃªn threshold - cÃ³ thá»ƒ cÃ³ cáº£ 2 classes")
                    print(f"      Thá»­ vá»›i threshold tháº¥p hÆ¡n cÃ³ thá»ƒ giÃºp phÃ¢n biá»‡t tá»‘t hÆ¡n")
                elif test_probs.max() < current_thresh:
                    suggested_threshold = np.percentile(test_probs, 50)
                    print(f"   âš ï¸  Táº¤T Cáº¢ probabilities Ä‘á»u dÆ°á»›i threshold {current_thresh}")
                    print(f"   ğŸ’¡ Äá» xuáº¥t giáº£m threshold xuá»‘ng {suggested_threshold:.4f} (median) Ä‘á»ƒ phÃ¢n biá»‡t classes")
                    print(f"   ğŸ”„ Äang Ä‘iá»u chá»‰nh threshold...")
                    oracle_client.set_threshold(suggested_threshold)
                    test_predictions_new = oracle_client.predict(X_eval_s[test_indices])
                    test_dist_new = dict(zip(*np.unique(test_predictions_new, return_counts=True)))
                    print(f"   âœ… Vá»›i threshold má»›i {suggested_threshold:.4f}: {test_dist_new}")
                    
                    print(f"   ğŸ”„ Re-querying seed, val, eval vá»›i threshold má»›i...")
                    y_eval = oracle_client.predict(X_eval_s)
                    y_seed = oracle_client.predict(X_seed_s)
                    y_val = oracle_client.predict(X_val_s)
                    eval_dist = dict(zip(*np.unique(y_eval, return_counts=True)))
                    seed_dist = dict(zip(*np.unique(y_seed, return_counts=True)))
                    val_dist = dict(zip(*np.unique(y_val, return_counts=True)))
                    print(f"   âœ… Distribution sau khi Ä‘iá»u chá»‰nh threshold:")
                    print(f"      Eval: {eval_dist}")
                    print(f"      Seed: {seed_dist}")
                    print(f"      Val: {val_dist}")
            except Exception as e:
                print(f"   âš ï¸  KhÃ´ng thá»ƒ kiá»ƒm tra probabilities: {e}")

    metrics_history = []
    # Khá»Ÿi táº¡o labeled_X dá»±a trÃªn attacker_type
    # KNN, LGB, XGB, vÃ  TabNet cáº§n raw data, Keras/Dual/CNN cáº§n scaled data
    if attacker_type in ["lgb", "knn", "xgb", "tabnet"]:
        labeled_X = X_seed  # Raw data cho LGB vÃ  KNN
    else:
        labeled_X = X_seed_s  # Scaled data cho Keras/Dual/CNN
    labeled_y = y_seed

    def evaluate(model, round_id: int, total_labels: int):
        probs = np.squeeze(model(X_eval_s), axis=-1)
        
        # Tá»‘i Æ°u threshold dá»±a trÃªn F1-score vá»›i ground truth labels
        # Äiá»u nÃ y quan trá»ng vá»›i class imbalance nghiÃªm trá»ng
        thresholds = np.linspace(0.1, 0.9, 81)
        best_f1 = -1
        best_threshold = 0.5
        best_preds = (probs >= 0.5).astype(int)
        
        for thresh in thresholds:
            preds_thresh = (probs >= thresh).astype(int)
            _, _, f1_thresh, _ = precision_recall_fscore_support(
                y_eval_gt, preds_thresh, average="binary", zero_division=0
            )
            if f1_thresh > best_f1:
                best_f1 = f1_thresh
                best_threshold = thresh
                best_preds = preds_thresh
        
        # Sá»­ dá»¥ng threshold tá»‘i Æ°u
        preds = best_preds
        
        # QUAN TRá»ŒNG: Agreement = so sÃ¡nh predictions cá»§a surrogate vá»›i predictions cá»§a target model
        # Accuracy = so sÃ¡nh predictions cá»§a surrogate vá»›i ground truth labels
        agreement = (preds == y_eval).mean()  # y_eval lÃ  predictions tá»« target model (oracle)
        acc = accuracy_score(y_eval_gt, preds)  # y_eval_gt lÃ  ground truth labels
        acc_vs_oracle = accuracy_score(y_eval, preds)  # Accuracy so vá»›i oracle (giá»‘ng agreement nhÆ°ng dÃ¹ng accuracy_score)
        balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_eval_gt, preds, average="binary", zero_division=0
        )
        try:
            auc = roc_auc_score(y_eval_gt, probs)
        except ValueError:
            auc = float("nan")

        # TÃ­nh sá»‘ queries thá»±c táº¿ (khÃ´ng tÃ­nh seed vÃ  val)
        # á» round 0, total_labels chá»‰ lÃ  seed_size, nÃªn actual_queries = 0
        # Tá»« round 1 trá»Ÿ Ä‘i, total_labels = seed_size + queries_accumulated
        actual_queries = max(0, total_labels - seed_size)
        
        # Log metrics Ä‘á»ƒ giáº£i thÃ­ch sá»± khÃ¡c biá»‡t
        print(f"\nğŸ“Š Round {round_id} Evaluation:")
        print(f"   Agreement (vs Oracle): {agreement:.4f} ({agreement*100:.2f}%)")
        print(f"   Accuracy (vs Ground Truth): {acc:.4f} ({acc*100:.2f}%)")
        print(f"   Oracle Accuracy (vs Ground Truth): {oracle_acc_vs_gt:.4f} ({oracle_acc_vs_gt*100:.2f}%)")
        print(f"   ğŸ’¡ Giáº£i thÃ­ch: Val accuracy trong training ({agreement:.4f}) cao vÃ¬ so vá»›i oracle labels")
        print(f"   ğŸ’¡ Final accuracy ({acc:.4f}) tháº¥p hÆ¡n vÃ¬ so vá»›i ground truth (oracle khÃ´ng hoÃ n háº£o)")
        
        metrics = {
            "round": round_id,
            "labels_used": int(total_labels),
            "queries_used": int(actual_queries),  # Sá»‘ queries thá»±c táº¿ (chá»‰ tÃ­nh active learning)
            "optimal_threshold": float(best_threshold),
            "threshold_optimization_method": "f1_on_eval_set",  # Method dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
            "threshold_optimization_dataset": "eval_set_with_ground_truth",  # Dataset dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
            "surrogate_acc": float(acc),  # Accuracy vs Ground Truth
            "surrogate_acc_vs_oracle": float(acc_vs_oracle),  # Accuracy vs Oracle (tÆ°Æ¡ng tá»± agreement)
            "surrogate_balanced_acc": float(balanced_acc),  # Quan trá»ng vá»›i class imbalance
            "surrogate_auc": float(auc),
            "surrogate_precision": float(precision),
            "surrogate_recall": float(recall),
            "surrogate_f1": float(f1),
            "agreement_with_target": float(agreement),
            "oracle_acc_vs_gt": float(oracle_acc_vs_gt),  # Äá»™ chÃ­nh xÃ¡c cá»§a oracle vá»›i ground truth
        }
        metrics_history.append(metrics)
        return metrics

    # QUAN TRá»ŒNG: Theo nghiÃªn cá»©u, dÃ¹ng early_stopping=30 vÃ  num_epochs cao (100)
    # Ä‘á»ƒ model cÃ³ Ä‘á»§ thá»i gian há»c vÃ  trÃ¡nh underfitting
    # early_stopping=30: patience Ä‘á»§ lá»›n Ä‘á»ƒ vÆ°á»£t qua local minima
    # num_epochs: Ä‘á»§ epochs Ä‘á»ƒ model há»c tá»‘t vá»›i nhiá»u dá»¯ liá»‡u (máº·c Ä‘á»‹nh 100 theo nghiÃªn cá»©u)
    if attacker_type == "lgb":
        # LightGBM attacker khÃ´ng cáº§n scale data - Ä‘áº£m báº£o labeled_X lÃ  raw data
        if labeled_X is X_seed_s:
            labeled_X = X_seed  # Chuyá»ƒn sang raw data
        # Sá»­ dá»¥ng hyperparameters tá»‘i Æ°u Ä‘á»ƒ khá»›p vá»›i target model
        attacker = LGBAttacker(seed=seed)
        attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=2000, early_stopping=100)
        # Vá»›i LightGBM, khÃ´ng cáº§n scale data Ä‘á»ƒ evaluate
        def evaluate_lgb(model, round_id, total_labels):
            probs = model(X_eval)
            # LightGBM predict tráº£ vá» 1D array hoáº·c 2D array
            if probs.ndim > 1:
                probs = probs.flatten()
            
            # Tá»‘i Æ°u threshold dá»±a trÃªn F1-score vá»›i ground truth labels
            # Äiá»u nÃ y quan trá»ng vá»›i class imbalance nghiÃªm trá»ng
            thresholds = np.linspace(0.1, 0.9, 81)
            best_f1 = -1
            best_threshold = 0.5
            best_preds = (probs >= 0.5).astype(int)
            
            for thresh in thresholds:
                preds_thresh = (probs >= thresh).astype(int)
                _, _, f1_thresh, _ = precision_recall_fscore_support(
                    y_eval_gt, preds_thresh, average="binary", zero_division=0
                )
                if f1_thresh > best_f1:
                    best_f1 = f1_thresh
                    best_threshold = thresh
                    best_preds = preds_thresh
            
            # Sá»­ dá»¥ng threshold tá»‘i Æ°u
            preds = best_preds
            
            # QUAN TRá»ŒNG: Agreement = so sÃ¡nh predictions cá»§a surrogate vá»›i predictions cá»§a target model
            # Accuracy = so sÃ¡nh predictions cá»§a surrogate vá»›i ground truth labels
            agreement = (preds == y_eval).mean()  # y_eval lÃ  predictions tá»« target model (oracle)
            acc = accuracy_score(y_eval_gt, preds)  # y_eval_gt lÃ  ground truth labels
            acc_vs_oracle = accuracy_score(y_eval, preds)  # Accuracy so vá»›i oracle (giá»‘ng agreement nhÆ°ng dÃ¹ng accuracy_score)
            balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval_gt, preds, average="binary", zero_division=0
            )
            try:
                auc = roc_auc_score(y_eval_gt, probs)
            except ValueError:
                auc = float("nan")

            # TÃ­nh sá»‘ queries thá»±c táº¿ (khÃ´ng tÃ­nh seed, val khÃ´ng Ä‘Æ°á»£c thÃªm vÃ o pool)
            actual_queries = max(0, total_labels - seed_size)
            
            # Log metrics Ä‘á»ƒ giáº£i thÃ­ch sá»± khÃ¡c biá»‡t
            print(f"\nğŸ“Š Round {round_id} Evaluation:")
            print(f"   Agreement (vs Oracle): {agreement:.4f} ({agreement*100:.2f}%)")
            print(f"   Accuracy (vs Ground Truth): {acc:.4f} ({acc*100:.2f}%)")
            print(f"   Oracle Accuracy (vs Ground Truth): {oracle_acc_vs_gt:.4f} ({oracle_acc_vs_gt*100:.2f}%)")
            print(f"   ğŸ’¡ Giáº£i thÃ­ch: Val accuracy trong training ({agreement:.4f}) cao vÃ¬ so vá»›i oracle labels")
            print(f"   ğŸ’¡ Final accuracy ({acc:.4f}) tháº¥p hÆ¡n vÃ¬ so vá»›i ground truth (oracle khÃ´ng hoÃ n háº£o)")
            
            metrics = {
                "round": round_id,
                "labels_used": int(total_labels),
                "queries_used": int(actual_queries),  # Sá»‘ queries thá»±c táº¿ (chá»‰ tÃ­nh active learning)
                "optimal_threshold": float(best_threshold),
                "threshold_optimization_method": "f1_on_eval_set",  # Method dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
                "threshold_optimization_dataset": "eval_set_with_ground_truth",  # Dataset dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
                "surrogate_acc": float(acc),  # Accuracy vs Ground Truth
                "surrogate_acc_vs_oracle": float(acc_vs_oracle),  # Accuracy vs Oracle (tÆ°Æ¡ng tá»± agreement)
                "surrogate_balanced_acc": float(balanced_acc),  # Quan trá»ng vá»›i class imbalance
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
                "oracle_acc_vs_gt": float(oracle_acc_vs_gt),  # Äá»™ chÃ­nh xÃ¡c cá»§a oracle vá»›i ground truth
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_lgb
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    elif attacker_type == "dual":
        # DualDNN attacker cáº§n scale data vÃ  cáº£ ground truth labels (oracle predictions)
        # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
        attacker = KerasDualAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim,))
        # DualDNN train vá»›i (X, y_true) - y_true lÃ  oracle labels
        attacker.train_model(labeled_X, labeled_y, labeled_y, X_val_s, y_val, y_val, num_epochs=num_epochs)
        
        def evaluate_dual(model, round_id, total_labels):
            # DualDNN cáº§n cáº£ X vÃ  y_true (oracle labels) khi predict
            # __call__ nháº­n 2 tham sá»‘ riÃªng biá»‡t (X, y_true), khÃ´ng pháº£i tuple
            probs = np.squeeze(model(X_eval_s, y_eval), axis=-1)
            
            # Tá»‘i Æ°u threshold hoáº·c sá»­ dá»¥ng threshold cá»‘ Ä‘á»‹nh
            if fixed_threshold is not None:
                # Sá»­ dá»¥ng threshold cá»‘ Ä‘á»‹nh
                best_threshold = fixed_threshold
                preds = (probs >= best_threshold).astype(int)
                print(f"   ğŸ”§ Sá»­ dá»¥ng threshold cá»‘ Ä‘á»‹nh: {best_threshold:.3f}")
            else:
                # Tá»‘i Æ°u threshold dá»±a trÃªn metric Ä‘Æ°á»£c chá»n
                thresholds = np.linspace(0.1, 0.9, 81)
                best_metric_value = -1
                best_threshold = 0.5
                best_preds = (probs >= 0.5).astype(int)
                
                for thresh in thresholds:
                    preds_thresh = (probs >= thresh).astype(int)
                    
                    # TÃ­nh metric dá»±a trÃªn metric Ä‘Æ°á»£c chá»n
                    if threshold_optimization_metric == "f1":
                        _, _, metric_value, _ = precision_recall_fscore_support(
                            y_eval_gt, preds_thresh, average="binary", zero_division=0
                        )
                    elif threshold_optimization_metric == "accuracy":
                        metric_value = accuracy_score(y_eval_gt, preds_thresh)
                    elif threshold_optimization_metric == "balanced_accuracy":
                        metric_value = balanced_accuracy_score(y_eval_gt, preds_thresh)
                    else:
                        raise ValueError(
                            f"Unknown threshold_optimization_metric: {threshold_optimization_metric}. "
                            f"Chá»n má»™t trong: 'f1', 'accuracy', 'balanced_accuracy'"
                        )
                    
                    if metric_value > best_metric_value:
                        best_metric_value = metric_value
                        best_threshold = thresh
                        best_preds = preds_thresh
                
                # Sá»­ dá»¥ng threshold tá»‘i Æ°u
                preds = best_preds
                print(f"   ğŸ”§ Threshold tá»‘i Æ°u ({threshold_optimization_metric}): {best_threshold:.3f} (metric = {best_metric_value:.4f})")
            
            # Agreement vÃ  accuracy metrics
            agreement = (preds == y_eval).mean()
            acc = accuracy_score(y_eval_gt, preds)
            acc_vs_oracle = accuracy_score(y_eval, preds)
            balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval_gt, preds, average="binary", zero_division=0
            )
            try:
                auc = roc_auc_score(y_eval_gt, probs)
            except ValueError:
                auc = float("nan")
            
            # TÃ­nh sá»‘ queries thá»±c táº¿ (khÃ´ng tÃ­nh seed, val khÃ´ng Ä‘Æ°á»£c thÃªm vÃ o pool)
            actual_queries = max(0, total_labels - seed_size)
            
            print(f"\nğŸ“Š Round {round_id} Evaluation (DualDNN):")
            print(f"   Agreement (vs Oracle): {agreement:.4f} ({agreement*100:.2f}%)")
            print(f"   Accuracy (vs Ground Truth): {acc:.4f} ({acc*100:.2f}%)")
            print(f"   Oracle Accuracy (vs Ground Truth): {oracle_acc_vs_gt:.4f} ({oracle_acc_vs_gt*100:.2f}%)")
            
            metrics = {
                "round": round_id,
                "labels_used": int(total_labels),
                "queries_used": int(actual_queries),
                "optimal_threshold": float(best_threshold),
                "threshold_optimization_method": "f1_on_eval_set",  # Method dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
                "threshold_optimization_dataset": "eval_set_with_ground_truth",  # Dataset dÃ¹ng Ä‘á»ƒ tÃ¬m threshold
                "surrogate_acc": float(acc),
                "surrogate_acc_vs_oracle": float(acc_vs_oracle),
                "surrogate_balanced_acc": float(balanced_acc),
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
                "oracle_acc_vs_gt": float(oracle_acc_vs_gt),
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_dual
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    elif attacker_type == "cnn":
        # CNN attacker cáº§n scale data vÃ  reshape thÃ nh (n_samples, n_features, 1)
        # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
        attacker = CNNAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim, 1))
        attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)
        # CNN dÃ¹ng cÃ¹ng evaluate function nhÆ° keras (dÃ¹ng scaled data vÃ  np.squeeze)
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    elif attacker_type == "knn":
        # KNN attacker dÃ¹ng raw data Ä‘á»ƒ phÃ¹ há»£p vá»›i sklearn
        # Äáº£m báº£o labeled_X lÃ  raw data
        if labeled_X is X_seed_s:
            labeled_X = X_seed  # Chuyá»ƒn sang raw data
        # LÆ°u Ã½: KNN khÃ´ng cÃ³ validation set trong training, nhÆ°ng váº«n cáº§n X_val, y_val cho evaluate
        attacker = KNNAttacker(seed=seed)
        # KNN train vá»›i raw data
        attacker.train_model(labeled_X, labeled_y, X_val, y_val)
        
        def evaluate_knn(model, round_id, total_labels):
            # KNN cÃ³ thá»ƒ dÃ¹ng raw hoáº·c scaled data - dÃ¹ng raw Ä‘á»ƒ nháº¥t quÃ¡n
            probs = model(X_eval)
            # KNN predict tráº£ vá» 1D array
            if probs.ndim > 1:
                probs = probs.flatten()
            
            # Tá»‘i Æ°u threshold dá»±a trÃªn F1-score vá»›i ground truth labels
            thresholds = np.linspace(0.1, 0.9, 81)
            best_f1 = -1
            best_threshold = 0.5
            best_preds = (probs >= 0.5).astype(int)
            
            for thresh in thresholds:
                preds_thresh = (probs >= thresh).astype(int)
                _, _, f1_thresh, _ = precision_recall_fscore_support(
                    y_eval_gt, preds_thresh, average="binary", zero_division=0
                )
                if f1_thresh > best_f1:
                    best_f1 = f1_thresh
                    best_threshold = thresh
                    best_preds = preds_thresh
            
            preds = best_preds
            
            agreement = (preds == y_eval).mean()
            acc = accuracy_score(y_eval_gt, preds)
            acc_vs_oracle = accuracy_score(y_eval, preds)
            balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval_gt, preds, average="binary", zero_division=0
            )
            try:
                auc = roc_auc_score(y_eval_gt, probs)
            except ValueError:
                auc = float("nan")
            
            actual_queries = max(0, total_labels - seed_size)
            
            print(f"\nğŸ“Š Round {round_id} Evaluation (KNN):")
            print(f"   Agreement (vs Oracle): {agreement:.4f} ({agreement*100:.2f}%)")
            print(f"   Accuracy (vs Ground Truth): {acc:.4f} ({acc*100:.2f}%)")
            print(f"   Oracle Accuracy (vs Ground Truth): {oracle_acc_vs_gt:.4f} ({oracle_acc_vs_gt*100:.2f}%)")
            
            metrics = {
                "round": round_id,
                "labels_used": int(total_labels),
                "queries_used": int(actual_queries),
                "optimal_threshold": float(best_threshold),
                "threshold_optimization_method": "f1_on_eval_set",
                "threshold_optimization_dataset": "eval_set_with_ground_truth",
                "surrogate_acc": float(acc),
                "surrogate_acc_vs_oracle": float(acc_vs_oracle),
                "surrogate_balanced_acc": float(balanced_acc),
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
                "oracle_acc_vs_gt": float(oracle_acc_vs_gt),
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_knn
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    elif attacker_type == "xgb":
        # XGBoost attacker dÃ¹ng raw data (giá»‘ng LGB)
        # Äáº£m báº£o labeled_X lÃ  raw data
        if labeled_X is X_seed_s:
            labeled_X = X_seed  # Chuyá»ƒn sang raw data
        attacker = XGBoostAttacker(seed=seed)
        attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=200, early_stopping=20)
        
        # XGBoost dÃ¹ng raw data Ä‘á»ƒ evaluate (giá»‘ng LGB)
        def evaluate_xgb(model, round_id, total_labels):
            probs = model(X_eval)
            # XGBoost predict tráº£ vá» 1D array
            if probs.ndim > 1:
                probs = probs.flatten()
            
            # Tá»‘i Æ°u threshold dá»±a trÃªn F1-score vá»›i ground truth labels
            thresholds = np.linspace(0.1, 0.9, 81)
            best_f1 = -1
            best_threshold = 0.5
            best_preds = (probs >= 0.5).astype(int)
            
            for thresh in thresholds:
                preds_thresh = (probs >= thresh).astype(int)
                _, _, f1_thresh, _ = precision_recall_fscore_support(
                    y_eval_gt, preds_thresh, average="binary", zero_division=0
                )
                if f1_thresh > best_f1:
                    best_f1 = f1_thresh
                    best_threshold = thresh
                    best_preds = preds_thresh
            
            preds = best_preds
            
            agreement = (preds == y_eval).mean()
            acc = accuracy_score(y_eval_gt, preds)
            acc_vs_oracle = accuracy_score(y_eval, preds)
            balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval_gt, preds, average="binary", zero_division=0
            )
            
            try:
                auc = roc_auc_score(y_eval_gt, probs)
            except ValueError:
                auc = float("nan")
            
            metrics = {
                "round": round_id,
                "labels_used": total_labels,
                "surrogate_acc": float(acc),
                "surrogate_balanced_acc": float(balanced_acc),
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
                "optimal_threshold": float(best_threshold),
                "oracle_acc_vs_gt": float(oracle_acc_vs_gt),
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_xgb
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    elif attacker_type == "tabnet":
        # TabNet attacker dÃ¹ng raw data (giá»‘ng LGB vÃ  XGB)
        # Äáº£m báº£o labeled_X lÃ  raw data
        if labeled_X is X_seed_s:
            labeled_X = X_seed  # Chuyá»ƒn sang raw data
        attacker = TabNetAttacker(seed=seed)
        # TÄƒng sá»‘ epoch vÃ  patience Ä‘á»ƒ TabNet há»c tá»‘t hÆ¡n (nháº¥t lÃ  khi cÃ³ nhiá»u queries)
        attacker.train_model(
            labeled_X,
            labeled_y,
            X_val,
            y_val,
            max_epochs=100,
            patience=100000,  # effectively disable early stopping
            batch_size=2048,
        )
        
        # TabNet dÃ¹ng raw data Ä‘á»ƒ evaluate (giá»‘ng LGB vÃ  XGB)
        def evaluate_tabnet(model, round_id, total_labels):
            probs = model(X_eval)
            # TabNet predict_proba tráº£ vá» 1D hoáº·c 2D array
            if probs.ndim > 1:
                probs = probs.flatten()
            
            # Tá»‘i Æ°u threshold dá»±a trÃªn F1-score vá»›i ground truth labels
            thresholds = np.linspace(0.1, 0.9, 81)
            best_f1 = -1
            best_threshold = 0.5
            best_preds = (probs >= 0.5).astype(int)
            
            for thresh in thresholds:
                preds_thresh = (probs >= thresh).astype(int)
                _, _, f1_thresh, _ = precision_recall_fscore_support(
                    y_eval_gt, preds_thresh, average="binary", zero_division=0
                )
                if f1_thresh > best_f1:
                    best_f1 = f1_thresh
                    best_threshold = thresh
                    best_preds = preds_thresh
            
            preds = best_preds
            
            agreement = (preds == y_eval).mean()
            acc = accuracy_score(y_eval_gt, preds)
            acc_vs_oracle = accuracy_score(y_eval, preds)
            balanced_acc = balanced_accuracy_score(y_eval_gt, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval_gt, preds, average="binary", zero_division=0
            )
            
            try:
                auc = roc_auc_score(y_eval_gt, probs)
            except ValueError:
                auc = float("nan")
            
            metrics = {
                "round": round_id,
                "labels_used": total_labels,
                "surrogate_acc": float(acc),
                "surrogate_balanced_acc": float(balanced_acc),
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
                "optimal_threshold": float(best_threshold),
                "oracle_acc_vs_gt": float(oracle_acc_vs_gt),
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_tabnet
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    else:
        # Keras attacker cáº§n scale data
        # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
        attacker = KerasAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim,))
        attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])

    # Track tá»•ng queries Ä‘á»ƒ Ä‘áº£m báº£o chÃ­nh xÃ¡c
    # QUAN TRá»ŒNG: Query budget = seed + val + AL queries
    AL_queries_target = query_batch * num_rounds
    total_queries_target = seed_size + val_size + AL_queries_target  # Tá»•ng query budget
    total_queries_accumulated = seed_size + val_size  # Seed vÃ  val Ä‘Ã£ Ä‘Æ°á»£c query
    # Cho phÃ©p lá»‡ch tá»‘i Ä‘a 10% (dÆ° chá»© khÃ´ng Ä‘Æ°á»£c thiáº¿u)
    min_queries_acceptable = int(total_queries_target * 0.9)  # Ãt nháº¥t 90% cá»§a target
    max_queries_acceptable = int(total_queries_target * 1.1)  # Tá»‘i Ä‘a 110% cá»§a target
    
    print(f"\nğŸ“‹ Query Budget Tracking:")
    print(f"   Seed queries: {seed_size:,} (Ä‘Ã£ query)")
    print(f"   Val queries: {val_size:,} (Ä‘Ã£ query)")
    print(f"   AL queries target: {AL_queries_target:,} ({query_batch:,} queries/round Ã— {num_rounds} rounds)")
    print(f"   Total query budget: {total_queries_target:,} (seed + val + AL)")
    print(f"   Queries Ä‘Ã£ dÃ¹ng: {total_queries_accumulated:,} (seed + val)")
    print(f"   Queries cÃ²n láº¡i: {AL_queries_target:,} (AL queries)")
    print(f"   ğŸ“Š Cho phÃ©p lá»‡ch: {min_queries_acceptable:,} - {max_queries_acceptable:,} queries (90% - 110%)")
    print(f"   âš ï¸  Quan trá»ng: KhÃ´ng Ä‘Æ°á»£c thiáº¿u queries! (tá»‘i thiá»ƒu {min_queries_acceptable:,})")
    
    # Kiá»ƒm tra unlabeled pool cÃ³ Ä‘á»§ khÃ´ng
    if X_unlabeled_pool.shape[0] < AL_queries_target:
        print(f"\nâš ï¸  Cáº¢NH BÃO: Unlabeled pool ({X_unlabeled_pool.shape[0]:,}) < AL queries dá»± kiáº¿n ({AL_queries_target:,})")
        print(f"   ğŸ’¡ Unlabeled pool sáº½ cáº¡n kiá»‡t trÆ°á»›c khi Ä‘áº¡t Ä‘á»§ queries. Sáº½ cá»‘ gáº¯ng láº¥y tá»‘i Ä‘a cÃ³ thá»ƒ.")
    
    # Scale unlabeled pool náº¿u cáº§n (cho oracle query vÃ  attacker training)
    X_unlabeled_pool_s = None
    if oracle_model_type == "h5" or attacker_type in ["keras", "dual", "cnn"]:
        # Cáº§n scale cho oracle (náº¿u h5) hoáº·c attacker (náº¿u keras/dual/cnn)
        if scaler is None:
            # Táº¡o scaler tá»« seed, val, vÃ  unlabeled pool
            scaler = RobustScaler()
            scaler.fit(np.vstack([X_seed, X_val, X_unlabeled_pool]))
        X_unlabeled_pool_s = _clip_scale(scaler, X_unlabeled_pool)
    
    for query_round in range(1, num_rounds + 1):
        # Kiá»ƒm tra xem cÃ²n cáº§n bao nhiÃªu AL queries ná»¯a
        AL_queries_remaining_needed = AL_queries_target - (total_queries_accumulated - seed_size - val_size)
        
        # Náº¿u Ä‘Ã£ Ä‘áº¡t Ä‘á»§ AL queries, dá»«ng láº¡i
        if total_queries_accumulated >= total_queries_target:
            print(f"\nâœ… ÄÃ£ Ä‘áº¡t Ä‘á»§ query budget ({total_queries_target:,}). Dá»«ng active learning.")
            break
        
        # Náº¿u unlabeled pool cÃ²n láº¡i Ã­t hÆ¡n query_batch, váº«n cá»‘ gáº¯ng láº¥y tá»‘i Ä‘a cÃ³ thá»ƒ
        unlabeled_pool_remaining = X_unlabeled_pool.shape[0]
        queries_to_get_this_round = min(query_batch, unlabeled_pool_remaining, AL_queries_remaining_needed)
        
        if queries_to_get_this_round <= 0:
            print(f"\nâš ï¸  Round {query_round}: KhÃ´ng cÃ²n queries Ä‘á»ƒ láº¥y. Unlabeled pool: {unlabeled_pool_remaining}, Cáº§n: {AL_queries_remaining_needed}")
            break
        
        if unlabeled_pool_remaining < query_batch:
            print(f"\nâš ï¸  Round {query_round}: Unlabeled pool cÃ²n láº¡i ({unlabeled_pool_remaining}) < query_batch ({query_batch}).")
            print(f"   ğŸ”„ Sáº½ láº¥y tá»‘i Ä‘a {queries_to_get_this_round} queries tá»« unlabeled pool cÃ²n láº¡i.")
        
        # Cáº¢I TIáº¾N: Stratified Entropy Sampling vá»›i Pre-filtering báº±ng Thief Dataset Labels
        # Giáº£ Ä‘á»‹nh: Máº«u trong thief dataset Ä‘Ã£ biáº¿t nhÃ£n, máº«u tÆ°Æ¡ng tá»± trong pool sáº½ cÃ³ nhÃ£n tÆ°Æ¡ng tá»±
        # Sá»­ dá»¥ng labels cá»§a thief dataset Ä‘á»ƒ pre-filter pool trÆ°á»›c khi query oracle
        # Sau Ä‘Ã³ query oracle Ä‘á»ƒ xÃ¡c nháº­n labels thá»±c táº¿
        # Váº«n giá»¯ logic cÃ¢n báº±ng class
        print(f"\nğŸ”„ Round {query_round}: Äang chá»n queries báº±ng Stratified Entropy Sampling vá»›i Pre-filtering (thief dataset labels)...")
        
        # QUAN TRá»ŒNG: TÃ¡ch riÃªng unlabeled pool Ä‘á»ƒ query oracle vÃ  pool Ä‘á»ƒ train attacker
        # - Pool Ä‘á»ƒ query oracle: dá»±a trÃªn oracle_model_type (raw data cho LightGBM, scaled cho Keras)
        # - Pool Ä‘á»ƒ train attacker: dá»±a trÃªn attacker_type (scaled cho keras/dual, raw cho lgb)
        # Oracle query PHáº¢I dÃ¹ng data phÃ¹ há»£p vá»›i oracle model, khÃ´ng pháº£i attacker model!
        
        # Unlabeled pool Ä‘á»ƒ query oracle - dá»±a trÃªn oracle_model_type
        # QUAN TRá»ŒNG: Náº¿u oracle cÃ³ normalization stats, dÃ¹ng raw data (oracle tá»± normalize)
        if oracle_model_type == "h5":
            if oracle_has_normalization_stats:
                # Keras Oracle cÃ³ normalization stats: dÃ¹ng raw data (oracle tá»± normalize vÃ  clip)
                pool_for_oracle = X_unlabeled_pool
            else:
                # Keras Oracle khÃ´ng cÃ³ normalization stats: cáº§n scaled data
                pool_for_oracle = X_unlabeled_pool_s if X_unlabeled_pool_s is not None else X_unlabeled_pool
        else:
            # LightGBM Oracle: cáº§n raw data (KHÃ”NG scale!)
            pool_for_oracle = X_unlabeled_pool
        
        # Unlabeled pool Ä‘á»ƒ train attacker - dá»±a trÃªn attacker_type
        # xgb vÃ  tabnet khÃ´ng cáº§n scaling (giá»‘ng lgb vÃ  knn)
        if attacker_type in ["keras", "dual", "cnn"]:
            # Keras/Dual/CNN attacker: cáº§n scaled data
            pool_for_entropy = X_unlabeled_pool_s if X_unlabeled_pool_s is not None else X_unlabeled_pool
        else:
            # LightGBM/KNN attacker: cáº§n raw data
            pool_for_entropy = X_unlabeled_pool
        
        pool_size = pool_for_oracle.shape[0]  # DÃ¹ng pool_for_oracle Ä‘á»ƒ pre-filter
        
        # BÆ¯á»šC 1: Pre-filtering dá»±a trÃªn labels cá»§a thief dataset
        # Sá»­ dá»¥ng y_unlabeled_pool_gt (labels tá»« thief dataset) Ä‘á»ƒ chá»n pool cÃ¢n báº±ng TRÆ¯á»šC khi query oracle
        print(f"   ğŸ”„ Pre-filtering unlabeled pool dá»±a trÃªn labels cá»§a thief dataset...")
        pool_dist_gt_current = dict(zip(*np.unique(y_unlabeled_pool_gt, return_counts=True)))
        print(f"   ğŸ“Š Unlabeled pool distribution (thief dataset labels): {pool_dist_gt_current}")
        
        # Chá»n subset tá»« pool dá»±a trÃªn labels cá»§a thief dataset Ä‘á»ƒ Ä‘áº£m báº£o cÃ¢n báº±ng
        # Má»¥c tiÃªu: Chá»n Ä‘á»§ samples tá»« má»—i class Ä‘á»ƒ cÃ³ thá»ƒ chá»n queries cÃ¢n báº±ng sau nÃ y
        query_pool_size = min(pool_size, max(20000, queries_to_get_this_round * 10))
        
        # Stratified sampling tá»« pool dá»±a trÃªn thief dataset labels
        # Láº¥y 50% tá»« má»—i class (náº¿u cÃ³ Ä‘á»§)
        queries_per_class_for_pool = query_pool_size // 2
        
        pool_query_idx_list = []
        for class_label in [0, 1]:
            class_indices_in_pool = np.where(y_unlabeled_pool_gt == class_label)[0]
            if len(class_indices_in_pool) == 0:
                continue
            
            # Láº¥y tá»‘i Ä‘a queries_per_class_for_pool tá»« class nÃ y
            n_select_from_class = min(queries_per_class_for_pool, len(class_indices_in_pool))
            selected_indices = rng.choice(class_indices_in_pool, size=n_select_from_class, replace=False)
            pool_query_idx_list.append(selected_indices)
        
        if len(pool_query_idx_list) > 0:
            # Káº¿t há»£p indices tá»« cáº£ 2 classes
            pool_query_idx = np.concatenate(pool_query_idx_list)
            rng.shuffle(pool_query_idx)  # Shuffle Ä‘á»ƒ trá»™n classes
        else:
            # Fallback: Náº¿u khÃ´ng cÃ³ class nÃ o, dÃ¹ng toÃ n bá»™ unlabeled pool
            pool_query_idx = np.arange(pool_size)
        
        # Äáº£m báº£o khÃ´ng vÆ°á»£t quÃ¡ query_pool_size
        if len(pool_query_idx) > query_pool_size:
            pool_query_idx = pool_query_idx[:query_pool_size]
        
        # Láº¥y data tá»« pool_for_oracle (raw/scaled tÃ¹y oracle model type) Ä‘á»ƒ query oracle
        # QUAN TRá»ŒNG: Oracle query PHáº¢I dÃ¹ng pool_for_oracle, khÃ´ng pháº£i pool_for_entropy!
        X_pool_query = pool_for_oracle[pool_query_idx]
        y_pool_query_gt = y_unlabeled_pool_gt[pool_query_idx]  # Labels tá»« thief dataset (ground truth cá»§a unlabeled pool)
        
        # Log distribution sau pre-filtering
        pool_query_dist_gt = dict(zip(*np.unique(y_pool_query_gt, return_counts=True)))
        print(f"   âœ… Pre-filtered pool: {len(pool_query_idx)} samples (from {pool_size} total pool)")
        print(f"   ğŸ“Š Pre-filtered distribution (thief dataset labels): {pool_query_dist_gt}")
        print(f"   ğŸ” Using {'scaled' if oracle_model_type == 'h5' else 'raw'} data for oracle query (oracle is {oracle_model_type.upper()})")
        
        # BÆ¯á»šC 2: Query oracle Ä‘á»ƒ láº¥y labels thá»±c táº¿ tá»« target model
        # Äiá»u nÃ y xÃ¡c nháº­n labels thá»±c táº¿, cÃ³ thá»ƒ khÃ¡c vá»›i thief dataset labels
        # QUAN TRá»ŒNG: Oracle query dÃ¹ng X_pool_query tá»« pool_for_oracle (Ä‘Ãºng data type cho oracle)
        print(f"   ğŸ”„ Querying oracle Ä‘á»ƒ láº¥y labels thá»±c táº¿ tá»« target model...")
        y_pool_query = oracle_client.predict(X_pool_query)
        pool_query_dist = dict(zip(*np.unique(y_pool_query, return_counts=True)))
        print(f"   ğŸ“Š Pool distribution (oracle labels): {pool_query_dist}")
        
        # So sÃ¡nh labels tá»« thief dataset vs oracle
        agreement_thief_oracle = np.mean(y_pool_query_gt == y_pool_query)
        print(f"   ğŸ“Š Agreement (thief labels vs oracle labels): {agreement_thief_oracle:.4f} ({agreement_thief_oracle*100:.2f}%)")
        if agreement_thief_oracle < 0.7:
            print(f"   âš ï¸  WARNING: Thief labels vÃ  oracle labels khÃ¡c nhau nhiá»u (>30%)")
            print(f"   ğŸ’¡ Pre-filtering dá»±a trÃªn thief labels cÃ³ thá»ƒ khÃ´ng chÃ­nh xÃ¡c, nhÆ°ng váº«n dÃ¹ng oracle labels cho chá»n queries")
        else:
            print(f"   âœ… Thief labels vÃ  oracle labels khÃ¡ khá»›p - pre-filtering hiá»‡u quáº£")
        
        # BÆ¯á»šC 3: TÃ­nh entropy cho táº¥t cáº£ samples trong pool Ä‘Ã£ query
        # QUAN TRá»ŒNG: Sá»­ dá»¥ng oracle labels (y_pool_query) Ä‘á»ƒ chá»n queries, khÃ´ng pháº£i thief labels
        # vÃ¬ chÃºng ta cáº§n labels thá»±c táº¿ tá»« target model Ä‘á»ƒ Ä‘áº£m báº£o accuracy
        # Vá»›i dualDNN, cáº§n oracle labels cho entropy sampling
        
        # QUAN TRá»ŒNG: Äá»ƒ tÃ­nh entropy cho attacker, cáº§n dÃ¹ng pool_for_entropy (scaled cho keras/dual/cnn)
        # NhÆ°ng X_pool_query lÃ  tá»« pool_for_oracle (raw cho LightGBM oracle)
        # Cáº§n map vá» pool_for_entropy Ä‘á»ƒ tÃ­nh entropy Ä‘Ãºng
        # xgb vÃ  tabnet khÃ´ng cáº§n scaling (giá»‘ng lgb vÃ  knn)
        if attacker_type in ["keras", "dual", "cnn"] and oracle_model_type == "lgb":
            # Oracle lÃ  LightGBM (raw), nhÆ°ng attacker lÃ  keras/dual/cnn (cáº§n scaled)
            # Cáº§n láº¥y scaled version cá»§a X_pool_query Ä‘á»ƒ tÃ­nh entropy
            X_pool_query_for_entropy = pool_for_entropy[pool_query_idx]
        else:
            # Oracle vÃ  attacker cÃ¹ng data type, dÃ¹ng X_pool_query trá»±c tiáº¿p
            X_pool_query_for_entropy = X_pool_query
        
        pool_labels_for_entropy = y_pool_query if attacker_type == "dual" else np.zeros(X_pool_query.shape[0])
        dual_flag = (attacker_type == "dual")
        
        # TÃ­nh entropy cho táº¥t cáº£ samples
        entropy_candidates = X_pool_query.shape[0]
        q_idx_all = entropy_sampling(
            attacker, 
            X_pool_query_for_entropy,  # DÃ¹ng scaled data náº¿u attacker lÃ  keras/dual
            pool_labels_for_entropy,
            n_instances=entropy_candidates,
            dual=dual_flag
        )
        
        # BÆ¯á»šC 4: Chá»n queries cÃ¢n báº±ng tá»« má»—i class dá»±a trÃªn oracle labels
        # Má»¥c tiÃªu: 50% class 0, 50% class 1 (hoáº·c tá»· lá»‡ gáº§n nháº¥t cÃ³ thá»ƒ)
        queries_per_class = queries_to_get_this_round // 2
        query_idx_list = []
        
        for class_label in [0, 1]:
            # Lá»c indices cá»§a class nÃ y trong q_idx_all
            # q_idx_all lÃ  indices trong X_pool_query, Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo entropy giáº£m dáº§n
            class_mask = y_pool_query[q_idx_all] == class_label
            class_indices_in_q = np.where(class_mask)[0]  # Indices trong q_idx_all
            
            if len(class_indices_in_q) == 0:
                print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y class {class_label} trong pool")
                continue
            
            # Chá»n queries_per_class samples cÃ³ entropy cao nháº¥t tá»« class nÃ y
            # (q_idx_all Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo entropy giáº£m dáº§n)
            n_select = min(queries_per_class, len(class_indices_in_q))
            selected_indices_in_q = class_indices_in_q[:n_select]
            
            # Map tá»« indices trong q_idx_all sang indices trong X_pool_query
            # q_idx_all lÃ  indices trong X_pool_query (Ä‘Ã£ Ä‘Æ°á»£c sáº¯p xáº¿p theo entropy)
            selected_indices_in_pool_query = q_idx_all[selected_indices_in_q]
            
            # Map vá» indices trong pool gá»‘c (pool_for_entropy)
            # pool_query_idx lÃ  indices trong pool gá»‘c Ä‘Ã£ Ä‘Æ°á»£c pre-filter
            # selected_indices_in_pool_query lÃ  indices trong X_pool_query (subset)
            selected_pool_indices = pool_query_idx[selected_indices_in_pool_query]
            
            query_idx_list.append(selected_pool_indices)
            print(f"   âœ… Class {class_label}: Chá»n {n_select}/{len(class_indices_in_q)} samples (entropy cao nháº¥t)")
        
        # Káº¿t há»£p queries tá»« cáº£ 2 classes
        if len(query_idx_list) > 0:
            # query_idx_list chá»©a indices trong unlabeled pool gá»‘c (Ä‘Ã£ Ä‘Æ°á»£c map tá»« pool_query_idx)
            query_idx_in_unlabeled_pool = np.concatenate(query_idx_list)
        else:
            # Fallback: Náº¿u khÃ´ng cÃ³ class nÃ o, dÃ¹ng entropy sampling thÃ´ng thÆ°á»ng tá»« pool_query
            print(f"   âš ï¸  Fallback: DÃ¹ng entropy sampling thÃ´ng thÆ°á»ng tá»« pool_query (khÃ´ng cÃ³ class nÃ o)")
            entropy_candidates = min(10000, X_pool_query_for_entropy.shape[0])
            
            # Vá»›i dualDNN, dÃ¹ng labels Ä‘Ã£ query tá»« oracle
            pool_labels_for_entropy = y_pool_query if attacker_type == "dual" else np.zeros(X_pool_query_for_entropy.shape[0])
            
            # TÃ­nh entropy trÃªn pool_query (Ä‘Ã£ query oracle)
            q_idx = entropy_sampling(
                attacker, 
                X_pool_query_for_entropy, 
                pool_labels_for_entropy,
                n_instances=entropy_candidates,
                dual=dual_flag
            )
            X_med = X_pool_query_for_entropy[q_idx]
            num_clusters = min(queries_to_get_this_round, X_med.shape[0])
            if num_clusters > 0:
                kmed = KMedoids(n_clusters=num_clusters, init='k-medoids++', random_state=seed)
                kmed.fit(X_med)
                query_idx_in_med = kmed.medoid_indices_
                query_idx_in_pool_query = q_idx[query_idx_in_med]
            else:
                query_idx_in_pool_query = q_idx[:min(queries_to_get_this_round, len(q_idx))]
            
            # Map vá» indices trong unlabeled pool gá»‘c
            query_idx_in_unlabeled_pool = pool_query_idx[query_idx_in_pool_query]
        
        # Äáº£m báº£o khÃ´ng vÆ°á»£t quÃ¡ queries_to_get_this_round
        if len(query_idx_in_unlabeled_pool) > queries_to_get_this_round:
            query_idx_in_unlabeled_pool = query_idx_in_unlabeled_pool[:queries_to_get_this_round]
        
        print(f"   âœ… ÄÃ£ chá»n {len(query_idx_in_unlabeled_pool)} queries (target: {queries_to_get_this_round})")

        # Láº¥y data vÃ  labels cho queries Ä‘Ã£ chá»n
        # query_idx_in_unlabeled_pool lÃ  indices trong unlabeled pool gá»‘c
        # Cáº§n map vá» indices trong pool_query_idx Ä‘á»ƒ láº¥y labels tá»« y_pool_query
        
        # TÃ¬m vá»‹ trÃ­ cá»§a query_idx_in_unlabeled_pool trong pool_query_idx
        # pool_query_idx lÃ  indices trong unlabeled pool gá»‘c (Ä‘Ã£ Ä‘Æ°á»£c pre-filter)
        sorted_pool_query_idx = np.argsort(pool_query_idx)
        sorted_pool_query_values = pool_query_idx[sorted_pool_query_idx]
        positions = np.searchsorted(sorted_pool_query_values, query_idx_in_unlabeled_pool, side='left')
        valid_mask = (positions < len(sorted_pool_query_values)) & (sorted_pool_query_values[positions] == query_idx_in_unlabeled_pool)
        
        if not np.all(valid_mask):
            # Fallback: Query oracle trá»±c tiáº¿p cho cÃ¡c máº«u Ä‘Ã£ chá»n
            print(f"   âš ï¸  Má»™t sá»‘ queries khÃ´ng cÃ³ trong pool_query, sáº½ query oracle trá»±c tiáº¿p...")
            if oracle_model_type == "h5":
                X_query_for_oracle = X_unlabeled_pool_s[query_idx_in_unlabeled_pool] if X_unlabeled_pool_s is not None else X_unlabeled_pool[query_idx_in_unlabeled_pool]
            else:
                X_query_for_oracle = X_unlabeled_pool[query_idx_in_unlabeled_pool]
            y_query = oracle_client.predict(X_query_for_oracle)
        else:
            # Láº¥y labels tá»« y_pool_query (Ä‘Ã£ query oracle trong bÆ°á»›c pre-filtering)
            query_positions_in_pool_query = sorted_pool_query_idx[positions]
            y_query = y_pool_query[query_positions_in_pool_query]
        
        # Láº¥y data phÃ¹ há»£p vá»›i attacker_type (scaled cho keras/dual/cnn, raw cho lgb/knn/xgb/tabnet)
        if attacker_type in ["keras", "dual", "cnn"]:
            # Attacker cáº§n scaled data
            X_query_s = X_unlabeled_pool_s[query_idx_in_unlabeled_pool] if X_unlabeled_pool_s is not None else X_unlabeled_pool[query_idx_in_unlabeled_pool]
        else:
            # Attacker cáº§n raw data (lgb, knn)
            X_query_s = X_unlabeled_pool[query_idx_in_unlabeled_pool]

        # Log class distribution Ä‘á»ƒ kiá»ƒm tra
        query_dist = dict(zip(*np.unique(y_query, return_counts=True)))
        print(f"   ğŸ“Š Query distribution (sau stratified sampling): {query_dist}")
        
        # KIá»‚M TRA VÃ€ CÃ‚N Báº°NG CLASS DISTRIBUTION
        # Theo nghiÃªn cá»©u: Class imbalance cÃ³ thá»ƒ lÃ m model bias vá» class Ä‘a sá»‘
        # Giáº£i phÃ¡p: Äáº£m báº£o má»—i class cÃ³ Ã­t nháº¥t 30% queries (hoáº·c tá»‘i thiá»ƒu 100 samples)
        total_queries = len(y_query)
        if total_queries > 0:
            max_class_ratio = max(query_dist.values()) / total_queries
            min_class_samples = min(query_dist.values()) if len(query_dist) > 1 else 0
            min_required_samples = max(100, int(query_batch * 0.3))  # Tá»‘i thiá»ƒu 30% hoáº·c 100 samples
            
            if max_class_ratio > 0.7 or min_class_samples < min_required_samples:
                print(f"   âš ï¸  Class imbalance: Má»™t class chiáº¿m {max_class_ratio*100:.1f}%, class thiá»ƒu sá»‘ cÃ³ {min_class_samples} samples")
                print(f"   ğŸ’¡ Cáº§n tá»‘i thiá»ƒu {min_required_samples} samples cho má»—i class")
                
                # CÃ¢n báº±ng báº±ng cÃ¡ch láº¥y thÃªm samples tá»« class thiá»ƒu sá»‘
                if len(query_dist) == 2:
                    minority_class = min(query_dist.items(), key=lambda x: x[1])[0]
                    majority_class = max(query_dist.items(), key=lambda x: x[1])[0]
                    minority_count = query_dist[minority_class]
                    
                    if minority_count < min_required_samples:
                        needed_samples = min_required_samples - minority_count
                        print(f"   ğŸ”„ Cáº§n thÃªm {needed_samples} samples tá»« class {minority_class}...")
                        
                        # Query oracle trÃªn toÃ n bá»™ unlabeled pool cÃ²n láº¡i Ä‘á»ƒ tÃ¬m class thiá»ƒu sá»‘
                        remaining_pool_size = X_unlabeled_pool.shape[0]
                        if remaining_pool_size > needed_samples:
                            # TÄƒng sample_size Ä‘á»ƒ tÃ¬m Ä‘á»§ class thiá»ƒu sá»‘ (cÃ³ thá»ƒ pool chá»§ yáº¿u lÃ  class Ä‘a sá»‘)
                            # Æ¯á»›c tÃ­nh: náº¿u class thiá»ƒu sá»‘ chiáº¿m ~10%, cáº§n query ~10x Ä‘á»ƒ tÃ¬m Ä‘á»§
                            sample_size = min(needed_samples * 10, remaining_pool_size)
                            candidate_idx = rng.choice(remaining_pool_size, size=sample_size, replace=False)
                            
                            # Láº¥y data phÃ¹ há»£p vá»›i oracle type
                            if oracle_model_type == "h5":
                                X_candidates = X_unlabeled_pool_s[candidate_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[candidate_idx]
                            else:
                                X_candidates = X_unlabeled_pool[candidate_idx]
                            
                            y_candidates = oracle_client.predict(X_candidates)
                            
                            # Lá»c chá»‰ láº¥y class thiá»ƒu sá»‘
                            minority_mask = y_candidates == minority_class
                            minority_found = np.sum(minority_mask)
                            
                            if minority_found >= needed_samples:
                                # Láº¥y Ä‘á»§ samples tá»« class thiá»ƒu sá»‘
                                minority_candidate_idx = candidate_idx[minority_mask][:needed_samples]
                                
                                # Láº¥y data phÃ¹ há»£p vá»›i attacker type
                                if attacker_type in ["keras", "dual", "cnn"]:
                                    X_additional = X_unlabeled_pool_s[minority_candidate_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[minority_candidate_idx]
                                else:
                                    X_additional = X_unlabeled_pool[minority_candidate_idx]
                                
                                y_additional = y_candidates[minority_mask][:needed_samples]
                                
                                X_query_s = np.vstack([X_query_s, X_additional])
                                y_query = np.concatenate([y_query, y_additional])
                                # ThÃªm vÃ o query_idx_in_unlabeled_pool
                                query_idx_in_unlabeled_pool = np.concatenate([query_idx_in_unlabeled_pool, minority_candidate_idx])
                                
                                balanced_dist = dict(zip(*np.unique(y_query, return_counts=True)))
                                print(f"   âœ… ÄÃ£ cÃ¢n báº±ng: {balanced_dist}")
                            else:
                                print(f"   âš ï¸  Chá»‰ tÃ¬m tháº¥y {minority_found}/{needed_samples} samples tá»« class {minority_class}")
                                if minority_found > 0:
                                    minority_candidate_idx = candidate_idx[minority_mask]
                                    
                                    # Láº¥y data phÃ¹ há»£p vá»›i attacker type
                                    if attacker_type in ["keras", "dual", "cnn"]:
                                        X_additional = X_unlabeled_pool_s[minority_candidate_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[minority_candidate_idx]
                                    else:
                                        X_additional = X_unlabeled_pool[minority_candidate_idx]
                                    
                                    y_additional = y_candidates[minority_mask]
                                    X_query_s = np.vstack([X_query_s, X_additional])
                                    y_query = np.concatenate([y_query, y_additional])
                                    query_idx_in_unlabeled_pool = np.concatenate([query_idx_in_unlabeled_pool, minority_candidate_idx])
                                    
                                    final_dist = dict(zip(*np.unique(y_query, return_counts=True)))
                                    final_ratio = min(final_dist.values()) / sum(final_dist.values())
                                    print(f"   âœ… ÄÃ£ thÃªm {minority_found} samples, distribution: {final_dist} (minority ratio: {final_ratio*100:.1f}%)")
                                else:
                                    print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y samples tá»« class {minority_class} trong unlabeled pool cÃ²n láº¡i")
                                    print(f"   ğŸ’¡ CÃ³ thá»ƒ unlabeled pool cÃ²n láº¡i chá»§ yáº¿u lÃ  class {majority_class}")
                elif len(query_dist) == 1:
                    print(f"   âš ï¸  Cáº¢NH BÃO: Chá»‰ cÃ³ 1 class trong queries! Model sáº½ khÃ´ng há»c Ä‘Æ°á»£c phÃ¢n biá»‡t 2 classes")
                    # Thá»­ láº¥y thÃªm má»™t sá»‘ random samples Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ cáº£ 2 classes
                    remaining_pool_size = X_unlabeled_pool.shape[0]
                    if remaining_pool_size > 0:
                        additional_samples = min(200, remaining_pool_size, query_batch // 2)  # Láº¥y thÃªm 50% hoáº·c tá»‘i Ä‘a 200
                        additional_idx = rng.choice(remaining_pool_size, size=additional_samples, replace=False)
                        
                        # Láº¥y data phÃ¹ há»£p vá»›i oracle type
                        if oracle_model_type == "h5":
                            X_additional_for_query = X_unlabeled_pool_s[additional_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[additional_idx]
                        else:
                            X_additional_for_query = X_unlabeled_pool[additional_idx]
                        
                        y_additional = oracle_client.predict(X_additional_for_query)
                        additional_dist = dict(zip(*np.unique(y_additional, return_counts=True)))
                        print(f"   ğŸ”„ Láº¥y thÃªm {additional_samples} random samples: {additional_dist}")
                        
                        # ThÃªm vÃ o queries náº¿u cÃ³ class má»›i
                        if len(additional_dist) > len(query_dist) or any(c not in query_dist for c in additional_dist):
                            # Láº¥y data phÃ¹ há»£p vá»›i attacker type
                            if attacker_type in ["keras", "dual", "cnn"]:
                                X_additional = X_unlabeled_pool_s[additional_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[additional_idx]
                            else:
                                X_additional = X_unlabeled_pool[additional_idx]
                            
                            X_query_s = np.vstack([X_query_s, X_additional])
                            y_query = np.concatenate([y_query, y_additional])
                            query_idx_in_unlabeled_pool = np.concatenate([query_idx_in_unlabeled_pool, additional_idx])
                            print(f"   âœ… ÄÃ£ thÃªm samples, distribution má»›i: {dict(zip(*np.unique(y_query, return_counts=True)))}")

        # QUAN TRá»ŒNG: Äáº£m báº£o sá»‘ queries chÃ­nh xÃ¡c = queries_to_get_this_round
        # KHÃ”NG BAO GIá»œ Ä‘Æ°á»£c thiáº¿u queries trá»« khi pool thá»±c sá»± cáº¡n kiá»‡t!
        actual_queries = len(y_query)
        
        # TÃ­nh queries cÃ²n cáº§n Ä‘á»ƒ Ä‘áº¡t target
        queries_remaining_needed = total_queries_target - total_queries_accumulated
        
        # Má»¥c tiÃªu queries cho round nÃ y: khÃ´ng vÆ°á»£t quÃ¡ queries_remaining_needed vÃ  khÃ´ng vÆ°á»£t quÃ¡ 110% cá»§a query_batch
        max_queries_this_round = min(int(query_batch * 1.1), queries_remaining_needed) if queries_remaining_needed > 0 else int(query_batch * 1.1)
        min_queries_this_round = queries_to_get_this_round  # Ãt nháº¥t pháº£i Ä‘áº¡t má»¥c tiÃªu cho round nÃ y
        
        # QUAN TRá»ŒNG: Náº¿u thiáº¿u queries, Báº®T BUá»˜C pháº£i bá»• sung tá»« unlabeled pool
        # Chá»‰ cháº¥p nháº­n thiáº¿u náº¿u unlabeled pool thá»±c sá»± cáº¡n kiá»‡t
        if actual_queries < min_queries_this_round:
            # QUAN TRá»ŒNG: Náº¿u cÃ³ Ã­t hÆ¡n má»¥c tiÃªu, Báº®T BUá»˜C pháº£i bá»• sung
            needed_samples = min_queries_this_round - actual_queries
            print(f"   âš ï¸  CHá»ˆ CÃ“ {actual_queries}/{min_queries_this_round} queries. Cáº¦N Bá»” SUNG {needed_samples} queries!")
            
            remaining_pool_size = X_unlabeled_pool.shape[0]
            if remaining_pool_size >= needed_samples:
                # Láº¥y thÃªm random samples tá»« unlabeled pool cÃ²n láº¡i
                additional_idx = rng.choice(remaining_pool_size, size=needed_samples, replace=False)
                
                # Láº¥y data phÃ¹ há»£p vá»›i oracle type Ä‘á»ƒ query
                if oracle_model_type == "h5":
                    X_additional_for_query = X_unlabeled_pool_s[additional_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[additional_idx]
                else:
                    X_additional_for_query = X_unlabeled_pool[additional_idx]
                
                y_additional = oracle_client.predict(X_additional_for_query)
                
                # Láº¥y data phÃ¹ há»£p vá»›i attacker type
                if attacker_type in ["keras", "dual", "cnn"]:
                    X_additional = X_unlabeled_pool_s[additional_idx] if X_unlabeled_pool_s is not None else X_unlabeled_pool[additional_idx]
                else:
                    X_additional = X_unlabeled_pool[additional_idx]
                
                X_query_s = np.vstack([X_query_s, X_additional])
                y_query = np.concatenate([y_query, y_additional])
                query_idx_in_unlabeled_pool = np.concatenate([query_idx_in_unlabeled_pool, additional_idx])
                
                print(f"   âœ… ÄÃ£ bá»• sung {needed_samples} queries tá»« unlabeled pool. Total: {len(y_query)}")
                actual_queries = len(y_query)
            else:
                # Unlabeled pool khÃ´ng Ä‘á»§, láº¥y táº¥t cáº£ cÃ²n láº¡i
                pool_exhausted_flag = True
                if remaining_pool_size > 0:
                    # Láº¥y data phÃ¹ há»£p vá»›i oracle type Ä‘á»ƒ query
                    if oracle_model_type == "h5":
                        X_additional_for_query = X_unlabeled_pool_s if X_unlabeled_pool_s is not None else X_unlabeled_pool
                    else:
                        X_additional_for_query = X_unlabeled_pool
                    
                    y_additional = oracle_client.predict(X_additional_for_query)
                    
                    # Láº¥y data phÃ¹ há»£p vá»›i attacker type
                    if attacker_type in ["keras", "dual", "cnn"]:
                        X_additional = X_unlabeled_pool_s if X_unlabeled_pool_s is not None else X_unlabeled_pool
                    else:
                        X_additional = X_unlabeled_pool
                    
                    X_query_s = np.vstack([X_query_s, X_additional])
                    y_query = np.concatenate([y_query, y_additional])
                    all_indices = np.arange(X_unlabeled_pool.shape[0])
                    query_idx_in_unlabeled_pool = np.concatenate([query_idx_in_unlabeled_pool, all_indices])
                    
                    actual_queries = len(y_query)
                    print(f"   âš ï¸  Unlabeled pool cÃ²n láº¡i chá»‰ cÃ³ {remaining_pool_size} samples. ÄÃ£ láº¥y táº¥t cáº£.")
                    print(f"   ğŸ“Š Total queries trong round nÃ y: {actual_queries} (má»¥c tiÃªu: {min_queries_this_round})")
                    if actual_queries < min_queries_this_round:
                        missing = min_queries_this_round - actual_queries
                        print(f"   âŒ VáºªN THIáº¾U {missing} queries do unlabeled pool cáº¡n kiá»‡t!")
                else:
                    pool_exhausted_flag = True
                    print(f"   âŒ Lá»–I NGHIÃŠM TRá»ŒNG: Unlabeled pool Ä‘Ã£ cáº¡n kiá»‡t! Chá»‰ cÃ³ {actual_queries} queries thay vÃ¬ {min_queries_this_round}")
                    print(f"   âŒ Thiáº¿u {min_queries_this_round - actual_queries} queries! Äiá»u nÃ y sáº½ áº£nh hÆ°á»Ÿng nghiÃªm trá»ng Ä‘áº¿n hiá»‡u suáº¥t!")
        
        # Giá»›i háº¡n tá»‘i Ä‘a: khÃ´ng vÆ°á»£t quÃ¡ max_queries_this_round (110% cá»§a query_batch hoáº·c queries cÃ²n cáº§n)
        if actual_queries > max_queries_this_round:
            print(f"   âš ï¸  Class balancing Ä‘Ã£ thÃªm {actual_queries - max_queries_this_round} queries (vÆ°á»£t quÃ¡ 110%).")
            print(f"   ğŸ”„ Giá»›i háº¡n láº¡i vá» {max_queries_this_round} queries.")
            X_query_s = X_query_s[:max_queries_this_round]
            y_query = y_query[:max_queries_this_round]
            query_idx_in_unlabeled_pool = query_idx_in_unlabeled_pool[:max_queries_this_round]
            actual_queries = max_queries_this_round
            final_dist = dict(zip(*np.unique(y_query, return_counts=True)))
            print(f"   ğŸ“Š Query distribution sau khi giá»›i háº¡n: {final_dist}")
        
        final_query_count = actual_queries
        
        # QUAN TRá»ŒNG: Verify sá»‘ queries trÆ°á»›c khi thÃªm vÃ o labeled set
        queries_this_round = len(y_query)
        total_queries_accumulated += queries_this_round
        if total_queries_accumulated > total_queries_target:
            over_budget_flag = True
        
        # Kiá»ƒm tra xem cÃ³ Ä‘áº¡t má»¥c tiÃªu khÃ´ng
        if queries_this_round >= min_queries_this_round:
            status = "âœ…"
        else:
            status = "âš ï¸"
        
        print(f"   {status} Round {query_round}: ÄÃ£ chá»n {queries_this_round} queries (má»¥c tiÃªu: {min_queries_this_round}, tá»‘i Ä‘a: {max_queries_this_round})")
        print(f"   ğŸ“Š Tá»•ng queries tÃ­ch lÅ©y: {total_queries_accumulated:,}/{total_queries_target:,} ({total_queries_accumulated/total_queries_target*100:.1f}%)")
        
        # QUAN TRá»ŒNG: Verify queries_this_round Ä‘áº¡t má»¥c tiÃªu trÆ°á»›c khi xÃ³a tá»« unlabeled pool
        # Náº¿u thiáº¿u queries vÃ  unlabeled pool váº«n cÃ²n, pháº£i cáº£nh bÃ¡o nghiÃªm trá»ng
        if queries_this_round < min_queries_this_round:
            missing = min_queries_this_round - queries_this_round
            pool_remaining_before_delete = X_unlabeled_pool.shape[0]
            print(f"\n   âŒ Lá»–I NGHIÃŠM TRá»ŒNG: Round {query_round} chá»‰ cÃ³ {queries_this_round} queries thay vÃ¬ {min_queries_this_round}!")
            print(f"   âŒ Thiáº¿u {missing} queries! Äiá»u nÃ y sáº½ áº£nh hÆ°á»Ÿng nghiÃªm trá»ng Ä‘áº¿n hiá»‡u suáº¥t!")
            print(f"   ğŸ’¡ Unlabeled pool cÃ²n láº¡i trÆ°á»›c khi xÃ³a: {pool_remaining_before_delete:,} samples")
            print(f"   ğŸ’¡ Kiá»ƒm tra logic bá»• sung queries hoáº·c unlabeled pool size ban Ä‘áº§u!")
            # KHÃ”NG raise error vÃ¬ cÃ³ thá»ƒ unlabeled pool thá»±c sá»± cáº¡n kiá»‡t, nhÆ°ng cáº£nh bÃ¡o rÃµ rÃ ng
        
        # QUAN TRá»ŒNG: ThÃªm vÃ o labeled pool (pool tÃ­ch lÅ©y dáº§n)
        labeled_X = np.vstack([labeled_X, X_query_s])
        labeled_y = np.concatenate([labeled_y, y_query])

        # XÃ³a tá»« unlabeled pool (Ä‘áº£m báº£o query_idx_in_unlabeled_pool unique)
        query_idx_unique = np.unique(query_idx_in_unlabeled_pool)
        X_unlabeled_pool = np.delete(X_unlabeled_pool, query_idx_unique, axis=0)
        # QUAN TRá»ŒNG: CÅ©ng xÃ³a labels tÆ°Æ¡ng á»©ng tá»« y_unlabeled_pool_gt (thief dataset labels)
        y_unlabeled_pool_gt = np.delete(y_unlabeled_pool_gt, query_idx_unique, axis=0)
        
        if X_unlabeled_pool_s is not None:
            # X_unlabeled_pool_s cÃ³ sáºµn cho Keras, dualDNN, vÃ  CNN
            X_unlabeled_pool_s = np.delete(X_unlabeled_pool_s, query_idx_unique, axis=0)
        
        print(f"   ğŸ“Š Unlabeled pool cÃ²n láº¡i: {X_unlabeled_pool.shape[0]:,} samples")

        # QUAN TRá»ŒNG: Re-train tá»« Ä‘áº§u trÃªn toÃ n bá»™ dá»¯ liá»‡u tÃ­ch lÅ©y
        # Theo nghiÃªn cá»©u: Huáº¥n luyá»‡n láº¡i tá»« Ä‘áº§u giÃºp model há»c láº¡i phÃ¢n phá»‘i tá»•ng thá»ƒ,
        # giáº£m thiá»ƒu viá»‡c bá»‹ lá»‡ch theo phÃ¢n phá»‘i cá»§a lÃ´ dá»¯ liá»‡u má»›i nháº¥t
        print(f"   ğŸ”„ Re-training model vá»›i {labeled_X.shape[0]:,} labeled samples...")
        
        if attacker_type == "lgb":
            attacker = LGBAttacker(seed=seed)
            # Sá»­ dá»¥ng hyperparameters tá»‘i Æ°u Ä‘á»ƒ khá»›p vá»›i target model
            attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=2000, early_stopping=100)
        elif attacker_type == "dual":
            # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
            attacker = KerasDualAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim,))
            # DualDNN train vá»›i (X, y, y_true) - y_true lÃ  oracle labels
            attacker.train_model(labeled_X, labeled_y, labeled_y, X_val_s, y_val, y_val, num_epochs=num_epochs)
        elif attacker_type == "cnn":
            # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
            attacker = CNNAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim, 1))
            attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)
        elif attacker_type == "knn":
            attacker = KNNAttacker(seed=seed)
            # KNN dÃ¹ng raw data (labeled_X thay vÃ¬ scaled)
            attacker.train_model(labeled_X, labeled_y, X_val, y_val)
        elif attacker_type == "xgb":
            attacker = XGBoostAttacker(seed=seed)
            # XGBoost dÃ¹ng raw data (labeled_X thay vÃ¬ scaled)
            attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=200, early_stopping=20)
        elif attacker_type == "tabnet":
            attacker = TabNetAttacker(seed=seed)
            # TabNet dÃ¹ng raw data (labeled_X thay vÃ¬ scaled)
            attacker.train_model(
                labeled_X,
                labeled_y,
                X_val,
                y_val,
                max_epochs=100,
                patience=100000,  # effectively disable early stopping
                batch_size=2048,
            )
        else:
            # QUAN TRá»ŒNG: Sá»­ dá»¥ng surrogate_feature_dim (tá»« target model), khÃ´ng pháº£i dataset attack
            attacker = KerasAttacker(early_stopping=30, seed=seed, input_shape=(surrogate_feature_dim,))
            attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)

        evaluate(attacker, round_id=query_round, total_labels=labeled_X.shape[0])
    
    # Kiá»ƒm tra tá»•ng queries cuá»‘i cÃ¹ng
    final_total_queries = total_queries_accumulated
    diff = final_total_queries - total_queries_target
    diff_percent = (diff / total_queries_target * 100) if total_queries_target > 0 else 0
    query_gap_reason = "on_target"
    if final_total_queries < total_queries_target:
        query_gap_reason = "pool_exhausted" if pool_exhausted_flag else "stopped_before_target"
    elif final_total_queries > total_queries_target:
        query_gap_reason = "over_budget" if over_budget_flag else "extra_queries"
    
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Tá»”NG Káº¾T QUERIES:")
    print(f"{'='*80}")
    AL_queries_actual = final_total_queries - seed_size - val_size
    print(f"   Seed queries: {seed_size:,} (Ä‘Ã£ query)")
    print(f"   Val queries: {val_size:,} (Ä‘Ã£ query)")
    print(f"   AL queries dá»± kiáº¿n: {AL_queries_target:,} ({query_batch:,} queries/round Ã— {num_rounds} rounds)")
    print(f"   AL queries thá»±c táº¿: {AL_queries_actual:,}")
    print(f"   Total query budget dá»± kiáº¿n: {total_queries_target:,} (seed + val + AL)")
    print(f"   Total queries thá»±c táº¿: {final_total_queries:,}")
    print(f"   ChÃªnh lá»‡ch: {diff:+,} queries ({diff_percent:+.2f}%)")
    print(f"   NgÆ°á»¡ng cháº¥p nháº­n: {min_queries_acceptable:,} - {max_queries_acceptable:,} (90% - 110%)")
    
    if final_total_queries == total_queries_target:
        print(f"   âœ… Sá»‘ queries chÃ­nh xÃ¡c 100%!")
    elif final_total_queries >= min_queries_acceptable and final_total_queries <= max_queries_acceptable:
        if diff > 0:
            print(f"   âœ… Sá»‘ queries trong ngÆ°á»¡ng cháº¥p nháº­n (dÆ° {abs(diff):,} queries)")
        else:
            print(f"   âš ï¸  Sá»‘ queries trong ngÆ°á»¡ng cháº¥p nháº­n nhÆ°ng thiáº¿u {abs(diff):,} queries ({abs(diff_percent):.2f}%)")
    elif final_total_queries < min_queries_acceptable:
        print(f"   âŒ Lá»–I NGHIÃŠM TRá»ŒNG: Sá» QUERIES THIáº¾U QUÃ NHIá»€U! ({abs(diff_percent):.2f}% thiáº¿u)")
        print(f"   âŒ Thiáº¿u {abs(diff):,} queries! Äiá»u nÃ y sáº½ áº£nh hÆ°á»Ÿng NGHIÃŠM TRá»ŒNG Ä‘áº¿n hiá»‡u suáº¥t táº¥n cÃ´ng!")
        print(f"   ğŸ’¡ LÃ½ do cÃ³ thá»ƒ: Pool Ä‘Ã£ cáº¡n kiá»‡t trÆ°á»›c khi Ä‘áº¡t Ä‘á»§ queries")
        print(f"   âš ï¸  Cáº§n kiá»ƒm tra láº¡i:")
        print(f"      - Pool size ban Ä‘áº§u cÃ³ Ä‘á»§ khÃ´ng? (cáº§n Ã­t nháº¥t {total_queries_target:,} vá»›i buffer 20%)")
        print(f"      - Logic bá»• sung queries cÃ³ hoáº¡t Ä‘á»™ng Ä‘Ãºng khÃ´ng?")
        print(f"      - CÃ³ thá»ƒ cáº§n tÄƒng pool size hoáº·c Ä‘iá»u chá»‰nh query_batch/num_rounds")
        # KHÃ”NG raise error vÃ¬ váº«n muá»‘n cÃ³ káº¿t quáº£, nhÆ°ng cáº£nh bÃ¡o rÃµ rÃ ng
    else:
        print(f"   âš ï¸  Sá»‘ queries vÆ°á»£t quÃ¡ 10% (dÆ° {diff:,} queries, {diff_percent:.2f}%)")
    print(f"{'='*80}\n")

    output_dir.mkdir(parents=True, exist_ok=True)
    target_surrogate_dir = _resolve_optional_path(surrogate_dir) if surrogate_dir else output_dir.resolve()
    target_surrogate_dir.mkdir(parents=True, exist_ok=True)
    surrogate_basename = surrogate_name if surrogate_name else "surrogate_model"
    surrogate_path = target_surrogate_dir / surrogate_basename
    attacker.save_model(str(surrogate_path))
    
    # Láº¥y extension phÃ¹ há»£p vá»›i model type
    if attacker_type == "lgb":
        surrogate_model_path = f"{surrogate_path}.txt"
    elif attacker_type == "knn":
        surrogate_model_path = f"{surrogate_path}.pkl"
    elif attacker_type == "xgb":
        surrogate_model_path = f"{surrogate_path}.json"
    elif attacker_type == "tabnet":
        surrogate_model_path = f"{surrogate_path}.zip"
    else:
        # Keras, dualDNN, vÃ  CNN Ä‘á»u dÃ¹ng .h5
        surrogate_model_path = f"{surrogate_path}.h5"

    joblib_path = output_dir / "robust_scaler.joblib"
    try:
        if scaler is not None:
            import joblib
            joblib.dump(scaler, joblib_path)
        else:
            joblib_path = None
    except Exception:
        joblib_path = None

    df_metrics = pd.DataFrame(metrics_history)
    metrics_csv = output_dir / "extraction_metrics.csv"
    df_metrics.to_csv(metrics_csv, index=False)

    #region agent log
    try:
        import json as _json, time as _time
        from pathlib import Path as _Path
        _log_payload = {
            "sessionId": "debug-session",
            "runId": "pre-fix",
            "hypothesisId": "H2",
            "location": "extract_final_model.py:metrics_csv_write",
            "message": "metrics_history final snapshot before summary",
            "data": {
                "output_dir": str(output_dir),
                "metrics_len": len(metrics_history),
                "final_metrics": metrics_history[-1] if metrics_history else None,
                "metrics_csv": str(metrics_csv),
                "metrics_csv_exists_before": _Path(metrics_csv).exists(),
            },
            "timestamp": int(_time.time() * 1000),
        }
        with open("/home/hytong/Documents/model_extraction_malware/.cursor/debug.log", "a", encoding="utf-8") as _f:
            _f.write(_json.dumps(_log_payload, ensure_ascii=False) + "\n")
    except Exception:
        pass
    #endregion

    summary = {
        "oracle_source": oracle_source,
        "model_file_name": model_file_name,
        "model_type": model_type,
        "normalization_stats_path": normalization_stats_path,
        "attacker_type": attacker_type,
        "surrogate_model_path": surrogate_model_path,
        "scaler_path": str(joblib_path) if joblib_path else None,
        "metrics_csv": str(metrics_csv),
        "metrics": metrics_history,
        "seed_size": int(seed_size),
        "val_size": int(val_size),
        "query_batch": int(query_batch),
        "num_rounds": int(num_rounds),
        "total_queries_target": int(total_queries_target),
        "total_queries_actual": int(final_total_queries),
        "query_gap_reason": query_gap_reason,
    }

    summary_path = output_dir / "extraction_summary.json"
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2)

    return summary


if __name__ == "__main__":
    SUMMARY = run_extraction(
        weights_path=str(PROJECT_ROOT / "artifacts" / "targets" / "final_model.h5"),
        output_dir=PROJECT_ROOT / "output",
        seed=42,
    )
    print(json.dumps(SUMMARY["metrics"][-1], indent=2))

