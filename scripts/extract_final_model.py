import json
import os
import sys
from pathlib import Path
import gc

import numpy as np
import pandas as pd
import pyarrow.parquet as pq
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
from sklearn.preprocessing import RobustScaler

PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.attackers import KerasAttacker, LGBAttacker
from src.targets.flexible_target import FlexibleKerasTarget, FlexibleLGBTarget
from src.sampling import entropy_sampling
from sklearn_extra.cluster import KMedoids


def _clip_scale(scaler: RobustScaler, X: np.ndarray) -> np.ndarray:
    """Scale data v·ªõi RobustScaler v√† clip v·ªÅ [-5, 5] gi·ªëng pipeline g·ªëc."""
    transformed = scaler.transform(X)
    return np.clip(transformed, -5, 5)


def get_feature_columns(parquet_path: str, label_col: str = "Label") -> list:
    """L·∫•y danh s√°ch feature columns t·ª´ parquet file."""
    pq_file = pq.ParquetFile(parquet_path)
    return [name for name in pq_file.schema.names if name != label_col]


def load_data_from_parquet(
    parquet_path: str,
    feature_cols: list,
    label_col: str,
    skip_rows: int = 0,
    take_rows: int = None,
    shuffle: bool = False,
    batch_size: int = 10000,
    seed: int = None,
) -> tuple:
    """
    Load d·ªØ li·ªáu t·ª´ parquet file, lo·∫°i b·ªè label -1 v√† tr·∫£ v·ªÅ X, y.
    Gi·ªëng logic trong final_model.ipynb nh∆∞ng kh√¥ng normalize (s·∫Ω normalize sau).
    
    Args:
        seed: Random seed cho shuffle. N·∫øu None th√¨ d√πng np.random kh√¥ng c√≥ seed (kh√¥ng reproducible).
    """
    pq_file = pq.ParquetFile(parquet_path)
    all_X = []
    all_y = []
    rows_seen = 0
    emitted = 0
    removed_total = 0
    batch_count = 0

    try:
        total_batches = (pq_file.metadata.num_rows + batch_size - 1) // batch_size

        for batch in pq_file.iter_batches(batch_size=batch_size, columns=feature_cols + [label_col]):
            batch_count += 1
            batch_len = len(batch)
            batch_start = rows_seen
            rows_seen += batch_len

            if rows_seen <= skip_rows:
                if batch_count % 50 == 0:
                    print(f"  ‚è≥ ƒê√£ x·ª≠ l√Ω {batch_count}/{total_batches} batches (ƒëang skip)...")
                continue

            batch_df = batch.to_pandas()

            if skip_rows > batch_start:
                start_idx = skip_rows - batch_start
                batch_df = batch_df.iloc[start_idx:]

            if label_col in batch_df.columns:
                label_series = batch_df[label_col]
            else:
                alt_cols = [col for col in batch_df.columns if col.lower() == label_col.lower()]
                if alt_cols:
                    label_series = batch_df[alt_cols[0]]
                else:
                    raise KeyError(
                        f"Label column '{label_col}' kh√¥ng t·ªìn t·∫°i. C√°c c·ªôt: {list(batch_df.columns)[:5]}..."
                    )

            # Lo·∫°i b·ªè label -1 (unlabeled)
            valid_mask = label_series != -1
            if not np.any(valid_mask):
                removed_total += len(label_series)
                del batch_df, label_series
                gc.collect()
                continue

            removed_total += int(np.sum(~valid_mask))
            batch_df = batch_df[valid_mask]
            label_series = label_series[valid_mask]

            if take_rows is not None:
                remaining = take_rows - emitted
                if remaining <= 0:
                    break
                if len(batch_df) > remaining:
                    batch_df = batch_df.iloc[:remaining]
                    label_series = label_series.iloc[:remaining]

            if batch_df.empty:
                del batch_df, label_series
                gc.collect()
                continue

            X = batch_df[feature_cols].values.astype(np.float32)
            X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)
            y = label_series.values.astype(np.int32)

            all_X.append(X)
            all_y.append(y)
            emitted += len(X)

            if batch_count % 20 == 0:
                del batch_df, label_series
                gc.collect()
                if take_rows is None:
                    print(f"  ‚è≥ ƒê√£ x·ª≠ l√Ω {batch_count}/{total_batches} batches, loaded {emitted:,} samples...")
                else:
                    print(
                        f"  ‚è≥ ƒê√£ x·ª≠ l√Ω {batch_count}/{total_batches} batches, loaded {emitted:,}/{take_rows:,} samples..."
                    )
            else:
                del batch_df, label_series

            if take_rows is not None and emitted >= take_rows:
                break

        if all_X:
            X_concat = np.concatenate(all_X, axis=0)
            y_concat = np.concatenate(all_y, axis=0)
            del all_X, all_y
            gc.collect()
        else:
            X_concat = np.empty((0, len(feature_cols)), dtype=np.float32)
            y_concat = np.empty((0,), dtype=np.int32)

        if shuffle and len(X_concat) > 0:
            print(f"  üîÑ ƒêang shuffle {len(X_concat):,} samples...")
            if seed is not None:
                rng = np.random.default_rng(seed)
                indices = rng.permutation(len(X_concat))
            else:
                indices = np.random.permutation(len(X_concat))
            X_concat = X_concat[indices]
            y_concat = y_concat[indices]

        if removed_total > 0:
            print(f"  ‚ö†Ô∏è  ƒê√£ lo·∫°i b·ªè {removed_total:,} samples c√≥ label -1 (unlabeled)")

        return X_concat, y_concat
    finally:
        del pq_file
        gc.collect()


def run_extraction(
    weights_path: str,
    output_dir: Path,
    train_parquet: str = None,
    test_parquet: str = None,
    seed: int = 42,
    feature_dim: int = 2381,
    seed_size: int = 2000,
    val_size: int = 2000,
    eval_size: int = 4000,
    query_batch: int = 2000,
    num_rounds: int = 5,
    num_epochs: int = 5,
    model_type: str = "h5",  # "h5" ho·∫∑c "lgb"
    normalization_stats_path: str = None,  # C·∫ßn thi·∫øt n·∫øu model_type="lgb"
    attacker_type: str = None,  # "keras" ho·∫∑c "lgb", None ƒë·ªÉ t·ª± ƒë·ªông ch·ªçn theo model_type
) -> dict:
    rng = np.random.default_rng(seed)

    # Ch·ªâ set TF environment variables n·∫øu d√πng Keras model
    if model_type == "h5" or attacker_type == "keras":
        os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")
        os.environ.setdefault("TF_USE_LEGACY_KERAS", "1")

    label_col = "Label"
    
    # Auto-detect attacker_type n·∫øu kh√¥ng ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
    if attacker_type is None:
        attacker_type = "keras" if model_type == "h5" else "lgb"

    # Load d·ªØ li·ªáu t·ª´ EMBER parquet files
    if train_parquet is None:
        train_parquet = str(PROJECT_ROOT / "src" / "train_ember_2018_v2_features_label_other.parquet")
    if test_parquet is None:
        test_parquet = str(PROJECT_ROOT / "src" / "test_ember_2018_v2_features_label_other.parquet")

    print("=" * 60)
    print("üìä ƒêang load d·ªØ li·ªáu EMBER...")
    print("=" * 60)
    print(f"Train file: {train_parquet}")
    print(f"Test file: {test_parquet}")

    # L·∫•y feature columns v√† x√°c ƒë·ªãnh feature_dim th·ª±c t·∫ø
    feature_cols = get_feature_columns(train_parquet, label_col)
    actual_feature_dim = len(feature_cols)
    print(f"Feature columns: {actual_feature_dim}")
    
    # C·∫≠p nh·∫≠t feature_dim n·∫øu kh√°c v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh
    if actual_feature_dim != feature_dim:
        print(f"‚ö†Ô∏è  Feature dimension mismatch: dataset has {actual_feature_dim} features, "
              f"but feature_dim parameter is {feature_dim}")
        print(f"   Updating feature_dim to {actual_feature_dim} (t·ª´ dataset)")
        feature_dim = actual_feature_dim
    
    # T·∫°o oracle v·ªõi feature_dim ƒë√∫ng (sau khi ƒë√£ x√°c ƒë·ªãnh t·ª´ dataset)
    # Threshold m·∫∑c ƒë·ªãnh l√† 0.5 - c√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh n·∫øu oracle predict qu√° l·ªách
    print(f"\nüîÑ Kh·ªüi t·∫°o target model ({model_type.upper()}) v·ªõi feature_dim={feature_dim}...")
    
    if model_type == "lgb":
        # LightGBM model c·∫ßn normalization stats
        if normalization_stats_path is None:
            raise ValueError(
                "normalization_stats_path ph·∫£i ƒë∆∞·ª£c cung c·∫•p khi model_type='lgb'. "
                "Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n t·ªõi file normalization_stats.npz"
            )
        
        oracle = FlexibleLGBTarget(
            model_path=weights_path,
            normalization_stats_path=normalization_stats_path,
            threshold=0.5,
            name="lgb-target",
            feature_dim=feature_dim
        )
    else:
        # Keras/H5 model
        oracle = FlexibleKerasTarget(weights_path, feature_dim=feature_dim, threshold=0.5)
    
    required_feature_dim = oracle.get_required_feature_dim()
    
    if required_feature_dim is None:
        print(f"   ‚úÖ Target model c√≥ preprocessing layer - s·∫Ω t·ª± ƒë·ªông map t·ª´ {feature_dim} ƒë·∫∑c tr∆∞ng")
    else:
        print(f"   ‚úÖ Target model y√™u c·∫ßu {required_feature_dim} ƒë·∫∑c tr∆∞ng")
        if feature_dim > required_feature_dim:
            print(f"   ‚ö†Ô∏è  Dataset c√≥ {feature_dim} ƒë·∫∑c tr∆∞ng, s·∫Ω t·ª± ƒë·ªông c·∫Øt b·ªè {feature_dim - required_feature_dim} ƒë·∫∑c tr∆∞ng th·ª´a")
        elif feature_dim < required_feature_dim:
            print(f"   ‚ùå Dataset c√≥ {feature_dim} ƒë·∫∑c tr∆∞ng, nh∆∞ng target model y√™u c·∫ßu {required_feature_dim} ƒë·∫∑c tr∆∞ng")
            raise ValueError(f"Dataset kh√¥ng ƒë·ªß ƒë·∫∑c tr∆∞ng: {feature_dim} < {required_feature_dim}")

    # QUAN TR·ªåNG: ƒê·∫£m b·∫£o seed/val sets gi·ªëng nhau gi·ªØa c√°c configs
    # Gi·∫£i ph√°p: Load ƒë·ªß l·ªõn (seed_val + pool l·ªõn nh·∫•t), shuffle v·ªõi seed, sau ƒë√≥ chia
    # T√≠nh pool l·ªõn nh·∫•t c·∫ßn thi·∫øt trong c√°c configs (ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng thi·∫øu d·ªØ li·ªáu)
    # V·ªõi c·∫•u h√¨nh hi·ªán t·∫°i: max_queries_10000 c√≥ query_batch=2000, num_rounds=5 => pool c·∫ßn 10000
    max_pool_needed = query_batch * num_rounds
    seed_val_size = seed_size + val_size
    total_needed = seed_val_size + max_pool_needed
    
    print(f"\nüîÑ ƒêang load train data ({total_needed:,} samples: {seed_val_size:,} seed+val + {max_pool_needed:,} pool)...")
    X_train_all, _ = load_data_from_parquet(
        train_parquet, feature_cols, label_col, skip_rows=0, take_rows=total_needed, shuffle=True, seed=seed
    )
    print(f"‚úÖ Train data loaded: {X_train_all.shape}")

    # Chia train data th√†nh seed, val, pool
    # Seed v√† val gi·ªëng nhau cho t·∫•t c·∫£ configs
    idx_offset = 0
    X_seed = X_train_all[idx_offset : idx_offset + seed_size]
    idx_offset += seed_size

    X_val = X_train_all[idx_offset : idx_offset + val_size]
    idx_offset += val_size

    # Pool c√≥ th·ªÉ nh·ªè h∆°n max_pool_needed t√πy theo config
    # Nh∆∞ng v·∫´n l·∫•y t·ª´ c√πng m·ªôt ph·∫ßn c·ªßa d·ªØ li·ªáu ƒë√£ shuffle
    pool_needed = query_batch * num_rounds
    X_pool = X_train_all[idx_offset : idx_offset + pool_needed]
    del X_train_all
    gc.collect()

    # Load eval set t·ª´ test file
    print(f"\nüîÑ ƒêang load eval set ({eval_size:,} samples)...")
    X_eval, _ = load_data_from_parquet(
        test_parquet, feature_cols, label_col, skip_rows=0, take_rows=eval_size, shuffle=True, seed=seed
    )
    print(f"‚úÖ Eval set: {X_eval.shape}")

    print(f"\nüìä Data split:")
    print(f"  Seed: {X_seed.shape[0]:,}")
    print(f"  Val: {X_val.shape[0]:,}")
    print(f"  Pool: {X_pool.shape[0]:,}")
    print(f"  Eval: {X_eval.shape[0]:,}")

    # QUAN TR·ªåNG: X·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc khi query oracle
    # - V·ªõi Keras/H5 model: C·∫ßn scale data v·ªõi RobustScaler (model ƒë∆∞·ª£c train v·ªõi scaled data)
    # - V·ªõi LightGBM model: FlexibleLGBTarget s·∫Ω t·ª± ƒë·ªông normalize n·∫øu c√≥ normalization_stats_path
    #   Kh√¥ng c·∫ßn scale th√™m v·ªõi RobustScaler
    scaler = None
    X_eval_s = None
    X_seed_s = None
    X_val_s = None
    X_pool_s = None
    
    if model_type == "h5" or attacker_type == "keras":
        # Keras model c·∫ßn scale data
        print(f"\nüîÑ ƒêang scale d·ªØ li·ªáu tr∆∞·ªõc khi query oracle (Keras model)...")
        scaler = RobustScaler()
        scaler.fit(np.vstack([X_seed, X_val, X_pool]))

        X_eval_s = _clip_scale(scaler, X_eval)
        X_seed_s = _clip_scale(scaler, X_seed)
        X_val_s = _clip_scale(scaler, X_val)
        X_pool_s = _clip_scale(scaler, X_pool)
        
        print(f"‚úÖ ƒê√£ scale d·ªØ li·ªáu")
        print(f"   - X_eval_s shape: {X_eval_s.shape}")
        print(f"   - X_seed_s shape: {X_seed_s.shape}")
        print(f"   - X_val_s shape: {X_val_s.shape}")
        print(f"   - X_pool_s shape: {X_pool_s.shape}")
        
        # L·∫•y nh√£n t·ª´ oracle (V·ªöI D·ªÆ LI·ªÜU ƒê√É SCALE)
        print(f"\nüîÑ ƒêang l·∫•y nh√£n t·ª´ oracle (v·ªõi d·ªØ li·ªáu ƒë√£ scale)...")
        y_eval = oracle(X_eval_s)
        y_seed = oracle(X_seed_s)
        y_val = oracle(X_val_s)
    else:
        # LightGBM model: FlexibleLGBTarget s·∫Ω t·ª± ƒë·ªông normalize
        print(f"\nüîÑ ƒêang l·∫•y nh√£n t·ª´ oracle (LightGBM s·∫Ω t·ª± ƒë·ªông normalize)...")
        y_eval = oracle(X_eval)
        y_seed = oracle(X_seed)
        y_val = oracle(X_val)
        
        # V·ªõi LightGBM, kh√¥ng c·∫ßn scale data
        X_eval_s = X_eval
        X_seed_s = X_seed
        X_val_s = X_val
        X_pool_s = X_pool
    print(f"‚úÖ Oracle labels retrieved")
    eval_dist = dict(zip(*np.unique(y_eval, return_counts=True)))
    seed_dist = dict(zip(*np.unique(y_seed, return_counts=True)))
    val_dist = dict(zip(*np.unique(y_val, return_counts=True)))
    print(f"  Eval distribution: {eval_dist}")
    print(f"  Seed distribution: {seed_dist}")
    print(f"  Val distribution: {val_dist}")
    
    # KI·ªÇM TRA: N·∫øu oracle predict t·∫•t c·∫£ l√† m·ªôt class, c√≥ th·ªÉ c√≥ v·∫•n ƒë·ªÅ
    all_distributions = [eval_dist, seed_dist, val_dist]
    all_single_class = all(len(d) == 1 for d in all_distributions)
    if all_single_class:
        print(f"\n‚ö†Ô∏è  C·∫¢NH B√ÅO: Oracle ƒëang predict t·∫•t c·∫£ l√† m·ªôt class duy nh·∫•t!")
        print(f"   ƒêi·ªÅu n√†y c√≥ th·ªÉ do:")
        print(f"   1. Oracle threshold qu√° cao/th·∫•p")
        print(f"   2. D·ªØ li·ªáu th·ª±c s·ª± ch·ªâ c√≥ m·ªôt class")
        print(f"   3. Oracle model c√≥ v·∫•n ƒë·ªÅ")
        print(f"   üí° S·∫Ω th·ª≠ ki·ªÉm tra probabilities v√† c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh threshold...")
        
        # Ki·ªÉm tra probabilities ƒë·ªÉ xem c√≥ ph·∫£i do threshold kh√¥ng
        try:
            test_sample_size = min(100, X_eval_s.shape[0])
            test_indices = rng.choice(X_eval_s.shape[0], size=test_sample_size, replace=False)
            # S·ª≠ d·ª•ng X_eval_s ƒë√£ ƒë∆∞·ª£c scale/normalize
            test_data = X_eval_s[test_indices]
            test_probs = oracle.predict_proba(test_data)
            print(f"   üìä Test probabilities tr√™n {test_sample_size} samples:")
            print(f"      Range: [{test_probs.min():.4f}, {test_probs.max():.4f}]")
            print(f"      Mean: {test_probs.mean():.4f}, Median: {np.median(test_probs):.4f}")
            print(f"      Threshold hi·ªán t·∫°i: {oracle.model_threshold}")
            
            # N·∫øu probabilities t·∫≠p trung g·∫ßn threshold, c√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh
            if test_probs.min() < oracle.model_threshold < test_probs.max():
                print(f"   üí° Probabilities c√≥ c·∫£ d∆∞·ªõi v√† tr√™n threshold - c√≥ th·ªÉ c√≥ c·∫£ 2 classes")
                print(f"      Th·ª≠ v·ªõi threshold th·∫•p h∆°n c√≥ th·ªÉ gi√∫p ph√¢n bi·ªát t·ªët h∆°n")
            elif test_probs.max() < oracle.model_threshold:
                # T·∫•t c·∫£ probabilities ƒë·ªÅu d∆∞·ªõi threshold - c·∫ßn gi·∫£m threshold
                suggested_threshold = np.percentile(test_probs, 50)  # Median
                print(f"   ‚ö†Ô∏è  T·∫§T C·∫¢ probabilities ƒë·ªÅu d∆∞·ªõi threshold {oracle.model_threshold}")
                print(f"   üí° ƒê·ªÅ xu·∫•t gi·∫£m threshold xu·ªëng {suggested_threshold:.4f} (median) ƒë·ªÉ ph√¢n bi·ªát classes")
                print(f"   üîÑ ƒêang ƒëi·ªÅu ch·ªânh threshold...")
                oracle.model_threshold = suggested_threshold
                # Test l·∫°i v·ªõi threshold m·ªõi
                test_predictions_new = oracle(X_eval_s[test_indices])
                test_dist_new = dict(zip(*np.unique(test_predictions_new, return_counts=True)))
                print(f"   ‚úÖ V·ªõi threshold m·ªõi {suggested_threshold:.4f}: {test_dist_new}")
                
                # QUAN TR·ªåNG: Re-query seed, val, eval v·ªõi threshold m·ªõi
                print(f"   üîÑ Re-querying seed, val, eval v·ªõi threshold m·ªõi...")
                # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (scaled ho·∫∑c raw t√πy theo model type)
                y_eval = oracle(X_eval_s)
                y_seed = oracle(X_seed_s)
                y_val = oracle(X_val_s)
                eval_dist = dict(zip(*np.unique(y_eval, return_counts=True)))
                seed_dist = dict(zip(*np.unique(y_seed, return_counts=True)))
                val_dist = dict(zip(*np.unique(y_val, return_counts=True)))
                print(f"   ‚úÖ Distribution sau khi ƒëi·ªÅu ch·ªânh threshold:")
                print(f"      Eval: {eval_dist}")
                print(f"      Seed: {seed_dist}")
                print(f"      Val: {val_dist}")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ ki·ªÉm tra probabilities: {e}")

    metrics_history = []
    labeled_X = X_seed_s
    labeled_y = y_seed

    def evaluate(model, round_id: int, total_labels: int):
        probs = np.squeeze(model(X_eval_s), axis=-1)
        preds = (probs >= 0.5).astype(int)
        agreement = (preds == y_eval).mean()
        acc = accuracy_score(y_eval, preds)
        precision, recall, f1, _ = precision_recall_fscore_support(
            y_eval, preds, average="binary", zero_division=0
        )
        try:
            auc = roc_auc_score(y_eval, probs)
        except ValueError:
            auc = float("nan")

        # T√≠nh s·ªë queries th·ª±c t·∫ø (kh√¥ng t√≠nh seed v√† val)
        actual_queries = total_labels - seed_size - val_size
        
        metrics = {
            "round": round_id,
            "labels_used": int(total_labels),
            "queries_used": int(actual_queries),  # S·ªë queries th·ª±c t·∫ø (ch·ªâ t√≠nh active learning)
            "surrogate_acc": float(acc),
            "surrogate_auc": float(auc),
            "surrogate_precision": float(precision),
            "surrogate_recall": float(recall),
            "surrogate_f1": float(f1),
            "agreement_with_target": float(agreement),
        }
        metrics_history.append(metrics)
        return metrics

    # QUAN TR·ªåNG: Theo nghi√™n c·ª©u, d√πng early_stopping=30 v√† num_epochs cao (100)
    # ƒë·ªÉ model c√≥ ƒë·ªß th·ªùi gian h·ªçc v√† tr√°nh underfitting
    # early_stopping=30: patience ƒë·ªß l·ªõn ƒë·ªÉ v∆∞·ª£t qua local minima
    # num_epochs: ƒë·ªß epochs ƒë·ªÉ model h·ªçc t·ªët v·ªõi nhi·ªÅu d·ªØ li·ªáu (m·∫∑c ƒë·ªãnh 100 theo nghi√™n c·ª©u)
    if attacker_type == "lgb":
        # LightGBM attacker kh√¥ng c·∫ßn scale data
        attacker = LGBAttacker(seed=seed)
        attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=100, early_stopping=15)
        # V·ªõi LightGBM, kh√¥ng c·∫ßn scale data ƒë·ªÉ evaluate
        def evaluate_lgb(model, round_id, total_labels):
            probs = model(X_eval)
            # LightGBM predict tr·∫£ v·ªÅ 1D array ho·∫∑c 2D array
            if probs.ndim > 1:
                probs = probs.flatten()
            preds = (probs >= 0.5).astype(int)
            agreement = (preds == y_eval).mean()
            acc = accuracy_score(y_eval, preds)
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_eval, preds, average="binary", zero_division=0
            )
            try:
                auc = roc_auc_score(y_eval, probs)
            except ValueError:
                auc = float("nan")

            # T√≠nh s·ªë queries th·ª±c t·∫ø (kh√¥ng t√≠nh seed v√† val)
            actual_queries = total_labels - seed_size - val_size
            
            metrics = {
                "round": round_id,
                "labels_used": int(total_labels),
                "queries_used": int(actual_queries),  # S·ªë queries th·ª±c t·∫ø (ch·ªâ t√≠nh active learning)
                "surrogate_acc": float(acc),
                "surrogate_auc": float(auc),
                "surrogate_precision": float(precision),
                "surrogate_recall": float(recall),
                "surrogate_f1": float(f1),
                "agreement_with_target": float(agreement),
            }
            metrics_history.append(metrics)
            return metrics
        
        evaluate = evaluate_lgb
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])
    else:
        # Keras attacker c·∫ßn scale data
        attacker = KerasAttacker(early_stopping=30, seed=seed, input_shape=(feature_dim,))
        attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)
        evaluate(attacker, round_id=0, total_labels=labeled_X.shape[0])

    for query_round in range(1, num_rounds + 1):
        if X_pool.shape[0] < query_batch:
            break
        
        # GI·∫¢I PH√ÅP 1: D√πng Entropy + k-medoids thay v√¨ random sampling
        # Theo nghi√™n c·ª©u: Entropy ƒë·ªÉ ch·ªçn ƒëi·ªÉm c√≥ ƒë·ªô b·∫•t ƒë·ªãnh cao,
        # sau ƒë√≥ k-medoids ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh ƒëa d·∫°ng v√† tr√°nh l·∫•y nhi·ªÅu ƒëi·ªÉm nhi·ªÖu
        print(f"\nüîÑ Round {query_round}: ƒêang ch·ªçn queries b·∫±ng Entropy + k-medoids...")
        
        # Ch·ªçn d·ªØ li·ªáu ƒë·ªÉ query d·ª±a tr√™n attacker type
        pool_for_entropy = X_pool_s if attacker_type == "keras" else X_pool
        
        # B∆∞·ªõc 1: D√πng entropy ƒë·ªÉ ch·ªçn 10000 ƒëi·ªÉm c√≥ ƒë·ªô b·∫•t ƒë·ªãnh cao
        # (k-medoids kh√¥ng scale t·ªët v·ªõi to√†n b·ªô pool)
        entropy_candidates = min(10000, pool_for_entropy.shape[0])
        q_idx = entropy_sampling(
            attacker, 
            pool_for_entropy, 
            np.zeros(pool_for_entropy.shape[0]),  # y kh√¥ng c·∫ßn thi·∫øt cho entropy
            n_instances=entropy_candidates,
            dual=False
        )
        X_med = pool_for_entropy[q_idx]
        
        # B∆∞·ªõc 2: D√πng k-medoids ƒë·ªÉ ch·ªçn query_batch ƒëi·ªÉm ƒë·∫°i di·ªán t·ª´ c√°c ƒëi·ªÉm entropy cao
        kmed = KMedoids(n_clusters=query_batch, init='k-medoids++', random_state=seed)
        kmed.fit(X_med)
        query_idx_in_med = kmed.medoid_indices_
        query_idx = q_idx[query_idx_in_med]
        
        print(f"   ‚úÖ ƒê√£ ch·ªçn {len(query_idx)} queries t·ª´ {entropy_candidates} entropy candidates")

        # Query oracle
        # - V·ªõi Keras: Query v·ªõi d·ªØ li·ªáu ƒë√£ scale (X_pool_s)
        # - V·ªõi LightGBM: Query v·ªõi raw data (X_pool), FlexibleLGBTarget s·∫Ω t·ª± ƒë·ªông normalize
        X_query_s = pool_for_entropy[query_idx]
        y_query = oracle(X_query_s)

        # Log class distribution ƒë·ªÉ ki·ªÉm tra imbalance
        query_dist = dict(zip(*np.unique(y_query, return_counts=True)))
        print(f"   üìä Query distribution: {query_dist}")
        
        # KI·ªÇM TRA V√Ä C√ÇN B·∫∞NG CLASS DISTRIBUTION
        # Theo nghi√™n c·ª©u: Class imbalance c√≥ th·ªÉ l√†m model bias v·ªÅ class ƒëa s·ªë
        # Gi·∫£i ph√°p: ƒê·∫£m b·∫£o m·ªói class c√≥ √≠t nh·∫•t 30% queries (ho·∫∑c t·ªëi thi·ªÉu 100 samples)
        total_queries = len(y_query)
        if total_queries > 0:
            max_class_ratio = max(query_dist.values()) / total_queries
            min_class_samples = min(query_dist.values()) if len(query_dist) > 1 else 0
            min_required_samples = max(100, int(query_batch * 0.3))  # T·ªëi thi·ªÉu 30% ho·∫∑c 100 samples
            
            if max_class_ratio > 0.7 or min_class_samples < min_required_samples:
                print(f"   ‚ö†Ô∏è  Class imbalance: M·ªôt class chi·∫øm {max_class_ratio*100:.1f}%, class thi·ªÉu s·ªë c√≥ {min_class_samples} samples")
                print(f"   üí° C·∫ßn t·ªëi thi·ªÉu {min_required_samples} samples cho m·ªói class")
                
                # C√¢n b·∫±ng b·∫±ng c√°ch l·∫•y th√™m samples t·ª´ class thi·ªÉu s·ªë
                if len(query_dist) == 2:
                    minority_class = min(query_dist.items(), key=lambda x: x[1])[0]
                    majority_class = max(query_dist.items(), key=lambda x: x[1])[0]
                    minority_count = query_dist[minority_class]
                    
                    if minority_count < min_required_samples:
                        needed_samples = min_required_samples - minority_count
                        print(f"   üîÑ C·∫ßn th√™m {needed_samples} samples t·ª´ class {minority_class}...")
                        
                        # Query oracle tr√™n to√†n b·ªô pool c√≤n l·∫°i ƒë·ªÉ t√¨m class thi·ªÉu s·ªë
                        remaining_pool_size = X_pool_s.shape[0]
                        if remaining_pool_size > needed_samples:
                            # TƒÉng sample_size ƒë·ªÉ t√¨m ƒë·ªß class thi·ªÉu s·ªë (c√≥ th·ªÉ pool ch·ªß y·∫øu l√† class ƒëa s·ªë)
                            # ∆Ø·ªõc t√≠nh: n·∫øu class thi·ªÉu s·ªë chi·∫øm ~10%, c·∫ßn query ~10x ƒë·ªÉ t√¨m ƒë·ªß
                            sample_size = min(needed_samples * 10, remaining_pool_size)
                            candidate_idx = rng.choice(remaining_pool_size, size=sample_size, replace=False)
                            X_candidates = X_pool_s[candidate_idx]
                            y_candidates = oracle(X_candidates)
                            
                            # L·ªçc ch·ªâ l·∫•y class thi·ªÉu s·ªë
                            minority_mask = y_candidates == minority_class
                            minority_found = np.sum(minority_mask)
                            
                            if minority_found >= needed_samples:
                                # L·∫•y ƒë·ªß samples t·ª´ class thi·ªÉu s·ªë
                                minority_indices = candidate_idx[minority_mask][:needed_samples]
                                X_additional = X_pool_s[minority_indices]
                                y_additional = oracle(X_additional)
                                
                                X_query_s = np.vstack([X_query_s, X_additional])
                                y_query = np.concatenate([y_query, y_additional])
                                query_idx = np.concatenate([query_idx, minority_indices])
                                
                                balanced_dist = dict(zip(*np.unique(y_query, return_counts=True)))
                                print(f"   ‚úÖ ƒê√£ c√¢n b·∫±ng: {balanced_dist}")
                            else:
                                print(f"   ‚ö†Ô∏è  Ch·ªâ t√¨m th·∫•y {minority_found}/{needed_samples} samples t·ª´ class {minority_class}")
                                if minority_found > 0:
                                    minority_indices = candidate_idx[minority_mask]
                                    X_additional = X_pool_s[minority_indices]
                                    y_additional = oracle(X_additional)
                                    X_query_s = np.vstack([X_query_s, X_additional])
                                    y_query = np.concatenate([y_query, y_additional])
                                    query_idx = np.concatenate([query_idx, minority_indices])
                                    
                                    final_dist = dict(zip(*np.unique(y_query, return_counts=True)))
                                    final_ratio = min(final_dist.values()) / sum(final_dist.values())
                                    print(f"   ‚úÖ ƒê√£ th√™m {minority_found} samples, distribution: {final_dist} (minority ratio: {final_ratio*100:.1f}%)")
                                else:
                                    print(f"   ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y samples t·ª´ class {minority_class} trong pool c√≤n l·∫°i")
                                    print(f"   üí° C√≥ th·ªÉ pool c√≤n l·∫°i ch·ªß y·∫øu l√† class {majority_class}")
                elif len(query_dist) == 1:
                    print(f"   ‚ö†Ô∏è  C·∫¢NH B√ÅO: Ch·ªâ c√≥ 1 class trong queries! Model s·∫Ω kh√¥ng h·ªçc ƒë∆∞·ª£c ph√¢n bi·ªát 2 classes")
                    # Th·ª≠ l·∫•y th√™m m·ªôt s·ªë random samples ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ c·∫£ 2 classes
                    remaining_pool_size = X_pool_s.shape[0]
                    if remaining_pool_size > 0:
                        additional_samples = min(200, remaining_pool_size, query_batch // 2)  # L·∫•y th√™m 50% ho·∫∑c t·ªëi ƒëa 200
                        additional_idx = rng.choice(remaining_pool_size, size=additional_samples, replace=False)
                        X_additional = X_pool_s[additional_idx]
                        y_additional = oracle(X_additional)
                        additional_dist = dict(zip(*np.unique(y_additional, return_counts=True)))
                        print(f"   üîÑ L·∫•y th√™m {additional_samples} random samples: {additional_dist}")
                        
                        # Th√™m v√†o queries n·∫øu c√≥ class m·ªõi
                        if len(additional_dist) > len(query_dist) or any(c not in query_dist for c in additional_dist):
                            X_query_s = np.vstack([X_query_s, X_additional])
                            y_query = np.concatenate([y_query, y_additional])
                            query_idx = np.concatenate([query_idx, additional_idx])
                            print(f"   ‚úÖ ƒê√£ th√™m samples, distribution m·ªõi: {dict(zip(*np.unique(y_query, return_counts=True)))}")

        # QUAN TR·ªåNG: ƒê·∫£m b·∫£o s·ªë queries ch√≠nh x√°c = query_batch
        # N·∫øu class balancing th√™m queries, gi·ªõi h·∫°n l·∫°i v·ªÅ query_batch
        actual_queries = len(y_query)
        if actual_queries > query_batch:
            print(f"   ‚ö†Ô∏è  Class balancing ƒë√£ th√™m {actual_queries - query_batch} queries. "
                  f"Gi·ªõi h·∫°n l·∫°i v·ªÅ {query_batch} queries ƒë·ªÉ ƒë·∫£m b·∫£o s·ªë queries ch√≠nh x√°c.")
            # L·∫•y query_batch queries ƒë·∫ßu ti√™n (ƒë√£ ƒë∆∞·ª£c entropy + k-medoids ch·ªçn)
            X_query_s = X_query_s[:query_batch]
            y_query = y_query[:query_batch]
            query_idx = query_idx[:query_batch]
            final_dist = dict(zip(*np.unique(y_query, return_counts=True)))
            print(f"   üìä Query distribution sau khi gi·ªõi h·∫°n: {final_dist}")
        
        labeled_X = np.vstack([labeled_X, X_query_s])
        labeled_y = np.concatenate([labeled_y, y_query])

        # X√≥a t·ª´ pool
        X_pool = np.delete(X_pool, query_idx, axis=0)
        if attacker_type == "keras":
            # Ch·ªâ c√≥ X_pool_s n·∫øu d√πng Keras attacker
            X_pool_s = np.delete(X_pool_s, query_idx, axis=0)
        else:
            # V·ªõi LightGBM, X_pool_s = X_pool
            X_pool_s = X_pool

        # QUAN TR·ªåNG: Re-train t·ª´ ƒë·∫ßu tr√™n to√†n b·ªô d·ªØ li·ªáu t√≠ch l≈©y
        # Theo nghi√™n c·ª©u: Hu·∫•n luy·ªán l·∫°i t·ª´ ƒë·∫ßu gi√∫p model h·ªçc l·∫°i ph√¢n ph·ªëi t·ªïng th·ªÉ,
        # gi·∫£m thi·ªÉu vi·ªác b·ªã l·ªách theo ph√¢n ph·ªëi c·ªßa l√¥ d·ªØ li·ªáu m·ªõi nh·∫•t
        print(f"   üîÑ Re-training model v·ªõi {labeled_X.shape[0]:,} labeled samples...")
        
        if attacker_type == "lgb":
            attacker = LGBAttacker(seed=seed)
            attacker.train_model(labeled_X, labeled_y, X_val, y_val, boosting_rounds=1000, early_stopping=60)
        else:
            attacker = KerasAttacker(early_stopping=30, seed=seed, input_shape=(feature_dim,))
            attacker.train_model(labeled_X, labeled_y, X_val_s, y_val, num_epochs=num_epochs)

        evaluate(attacker, round_id=query_round, total_labels=labeled_X.shape[0])

    output_dir.mkdir(parents=True, exist_ok=True)
    surrogate_path = output_dir / "surrogate_model"
    attacker.save_model(str(surrogate_path))
    
    # L·∫•y extension ph√π h·ª£p v·ªõi model type
    if attacker_type == "lgb":
        surrogate_model_path = f"{surrogate_path}.txt"
    else:
        surrogate_model_path = f"{surrogate_path}.h5"

    joblib_path = output_dir / "robust_scaler.joblib"
    try:
        if scaler is not None:
            import joblib
            joblib.dump(scaler, joblib_path)
        else:
            joblib_path = None
    except Exception:
        joblib_path = None

    df_metrics = pd.DataFrame(metrics_history)
    metrics_csv = output_dir / "extraction_metrics.csv"
    df_metrics.to_csv(metrics_csv, index=False)

    summary = {
        "weights_path": weights_path,
        "model_type": model_type,
        "normalization_stats_path": normalization_stats_path,
        "attacker_type": attacker_type,
        "surrogate_model_path": surrogate_model_path,
        "scaler_path": str(joblib_path) if joblib_path else None,
        "metrics_csv": str(metrics_csv),
        "metrics": metrics_history,
    }

    summary_path = output_dir / "extraction_summary.json"
    with open(summary_path, "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2)

    return summary


if __name__ == "__main__":
    SUMMARY = run_extraction(
        weights_path=str(PROJECT_ROOT / "src" / "final_model.h5"),
        output_dir=PROJECT_ROOT / "src" / "output",
        seed=42,
    )
    print(json.dumps(SUMMARY["metrics"][-1], indent=2))

